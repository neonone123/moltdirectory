<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Generate, remix, and edit images using fal.ai's AI">
  <title>fal-text-to-image - OpenClaw Directory</title>
  <link rel="canonical" href="https://moltdirectory.com/image-video-generation/fal-text-to-image/">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ü¶û</text></svg>">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/style.css">
  <script>
    // Apply saved theme before page renders to prevent flash
    (function() {
      const savedTheme = localStorage.getItem('theme') || 'dark';
      if (savedTheme === 'light') {
        document.documentElement.setAttribute('data-theme', 'light');
      }
    })();
  </script>
</head>
<body>
  <header class="header">
    <div class="header-inner">
      <a href="/" class="logo">

        <span class="logo-text">OpenClaw Directory</span>
      </a>
      <nav class="header-links">
        <a href="/start-here/" class="header-link">Start Here</a>
        <a href="/security-auditor" class="header-link">Security Auditor</a>
        <a href="https://github.com/neonone123/moltdirectory/issues/new?template=add-skill.yml" class="header-link" target="_blank" rel="noopener">Add Skill</a>
        <button class="theme-toggle" aria-label="Toggle theme" onclick="toggleTheme()">
          <svg class="icon-moon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/></svg>
          <svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
        </button>
        <a href="https://www.reddit.com/r/OpenClawDirectory/" class="header-link" target="_blank" rel="noopener" aria-label="Community">
          <svg viewBox="0 0 16 16" fill="currentColor" width="28" height="28"><path d="M6.167 8a.83.83 0 0 0-.83.83c0 .459.372.84.83.831a.831.831 0 0 0 0-1.661m1.843 3.647c.315 0 1.403-.038 1.976-.611a.23.23 0 0 0 0-.306.213.213 0 0 0-.306 0c-.353.363-1.126.487-1.67.487-.545 0-1.308-.124-1.671-.487a.213.213 0 0 0-.306 0 .213.213 0 0 0 0 .306c.564.563 1.652.61 1.977.61zm.992-2.807c0 .458.373.83.831.83s.83-.381.83-.83a.831.831 0 0 0-1.66 0z"/><path d="M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0m-3.828-1.165c-.315 0-.602.124-.812.325-.801-.573-1.9-.945-3.121-.993l.534-2.501 1.738.372a.83.83 0 1 0 .83-.869.83.83 0 0 0-.744.468l-1.938-.41a.2.2 0 0 0-.153.028.2.2 0 0 0-.086.134l-.592 2.788c-1.24.038-2.358.41-3.17.992-.21-.2-.496-.324-.81-.324a1.163 1.163 0 0 0-.478 2.224q-.03.17-.029.353c0 1.795 2.091 3.256 4.669 3.256s4.668-1.451 4.668-3.256c0-.114-.01-.238-.029-.353.401-.181.688-.592.688-1.069 0-.65-.525-1.165-1.165-1.165"/></svg>
        </a>
      </nav>
    </div>
  </header>
  
          <section class="skill-page-header">
            <div class="skill-page-header-inner">
              <a href="/image-video-generation/" class="back-link">‚Üê Back to Image & Video Generation</a>
              <div class="skill-page-meta">
                <a href="/image-video-generation/" class="skill-page-category">Image & Video Generation</a>
                <span class="skill-page-author">by @delorenj</span>
              </div>
              <h1 class="skill-page-title">fal-text-to-image</h1>
              <p class="skill-page-desc">Generate, remix, and edit images using fal.ai's AI</p>
            </div>
          </section>
          <div class="skill-page-body">
            <article class="skill-page-content">
              <div class="skill-source-wrapper">
                <div class="skill-source-header">
                  <div class="skill-source-title">Source Code</div>
                  <button class="copy-btn" onclick="copySkillContent(this)">
                    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"/><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"/></svg>
                    Copy
                  </button>
                </div>
                <div class="markdown-content">
                  <h1>fal.ai Image Generation &amp; Editing Skill</h1>
<p>Professional AI-powered image workflows using fal.ai&#39;s state-of-the-art models including FLUX, Recraft V3, Imagen4, and more.</p>
<h2>Three Modes of Operation</h2>
<h3>1. Text-to-Image (fal-text-to-image)</h3>
<p>Generate images from scratch using text prompts</p>
<h3>2. Image Remix (fal-image-remix)</h3>
<p>Transform existing images while preserving composition</p>
<h3>3. Image Edit (fal-image-edit)</h3>
<p>Targeted inpainting and masked editing</p>
<h2>When to Use This Skill</h2>
<p>Trigger when user:</p>
<ul>
<li>Requests image generation from text descriptions</li>
<li>Wants to transform/remix existing images with AI</li>
<li>Needs to edit specific regions of images (inpainting)</li>
<li>Wants to create images with specific styles (vector, realistic, typography)</li>
<li>Needs high-resolution professional images (up to 2K)</li>
<li>Wants to use a reference image for style transfer</li>
<li>Mentions specific models like FLUX, Recraft, or Imagen</li>
<li>Asks for logo, poster, or brand-style image generation</li>
<li>Needs object removal or targeted modifications</li>
</ul>
<h2>Quick Start</h2>
<h3>Text-to-Image: Generate from Scratch</h3>
<pre><code class="language-bash"># Basic generation
uv run python fal-text-to-image &quot;A cyberpunk city at sunset with neon lights&quot;

# With specific model
uv run python fal-text-to-image -m flux-pro/v1.1-ultra &quot;Professional headshot&quot;

# With style reference
uv run python fal-text-to-image -i reference.jpg &quot;Mountain landscape&quot; -m flux-2/lora/edit
</code></pre>
<h3>Image Remix: Transform Existing Images</h3>
<pre><code class="language-bash"># Transform style while preserving composition
uv run python fal-image-remix input.jpg &quot;Transform into oil painting&quot;

# With strength control (0.0=original, 1.0=full transformation)
uv run python fal-image-remix photo.jpg &quot;Anime style character&quot; --strength 0.6

# Premium quality remix
uv run python fal-image-remix -m flux-1.1-pro image.jpg &quot;Professional portrait&quot;
</code></pre>
<h3>Image Edit: Targeted Modifications</h3>
<pre><code class="language-bash"># Edit with mask image (white=edit area, black=preserve)
uv run python fal-image-edit input.jpg mask.png &quot;Replace with flowers&quot;

# Auto-generate mask from text
uv run python fal-image-edit input.jpg --mask-prompt &quot;sky&quot; &quot;Make it sunset&quot;

# Remove objects
uv run python fal-image-edit photo.jpg mask.png &quot;Remove object&quot; --strength 1.0

# General editing (no mask)
uv run python fal-image-edit photo.jpg &quot;Enhance lighting and colors&quot;
</code></pre>
<h2>Model Selection Guide</h2>
<p>The script intelligently selects the best model based on task context:</p>
<h3><strong>flux-pro/v1.1-ultra</strong> (Default for High-Res)</h3>
<ul>
<li><strong>Best for</strong>: Professional photography, high-resolution outputs (up to 2K)</li>
<li><strong>Strengths</strong>: Photo realism, professional quality</li>
<li><strong>Use when</strong>: User needs publication-ready images</li>
<li><strong>Endpoint</strong>: <code>fal-ai/flux-pro/v1.1-ultra</code></li>
</ul>
<h3><strong>recraft/v3/text-to-image</strong> (SOTA Quality)</h3>
<ul>
<li><strong>Best for</strong>: Typography, vector art, brand-style images, long text</li>
<li><strong>Strengths</strong>: Industry-leading benchmark scores, precise text rendering</li>
<li><strong>Use when</strong>: Creating logos, posters, or text-heavy designs</li>
<li><strong>Endpoint</strong>: <code>fal-ai/recraft/v3/text-to-image</code></li>
</ul>
<h3><strong>flux-2</strong> (Best Balance)</h3>
<ul>
<li><strong>Best for</strong>: General-purpose image generation</li>
<li><strong>Strengths</strong>: Enhanced realism, crisp text, native editing</li>
<li><strong>Use when</strong>: Standard image generation needs</li>
<li><strong>Endpoint</strong>: <code>fal-ai/flux-2</code></li>
</ul>
<h3><strong>flux-2/lora</strong> (Custom Styles)</h3>
<ul>
<li><strong>Best for</strong>: Domain-specific styles, fine-tuned variations</li>
<li><strong>Strengths</strong>: Custom style adaptation</li>
<li><strong>Use when</strong>: User wants specific artistic styles</li>
<li><strong>Endpoint</strong>: <code>fal-ai/flux-2/lora</code></li>
</ul>
<h3><strong>flux-2/lora/edit</strong> (Style Transfer)</h3>
<ul>
<li><strong>Best for</strong>: Image-to-image editing with style references</li>
<li><strong>Strengths</strong>: Specialized style transfer</li>
<li><strong>Use when</strong>: User provides reference image with <code>-i</code> flag</li>
<li><strong>Endpoint</strong>: <code>fal-ai/flux-2/lora/edit</code></li>
</ul>
<h3><strong>imagen4/preview</strong> (Google Quality)</h3>
<ul>
<li><strong>Best for</strong>: High-quality general images</li>
<li><strong>Strengths</strong>: Google&#39;s highest quality model</li>
<li><strong>Use when</strong>: User specifically requests Imagen or Google models</li>
<li><strong>Endpoint</strong>: <code>fal-ai/imagen4/preview</code></li>
</ul>
<h3><strong>stable-diffusion-v35-large</strong> (Typography &amp; Style)</h3>
<ul>
<li><strong>Best for</strong>: Complex prompts, typography, style control</li>
<li><strong>Strengths</strong>: Advanced prompt understanding, resource efficiency</li>
<li><strong>Use when</strong>: Complex multi-element compositions</li>
<li><strong>Endpoint</strong>: <code>fal-ai/stable-diffusion-v35-large</code></li>
</ul>
<h3><strong>ideogram/v2</strong> (Typography Specialist)</h3>
<ul>
<li><strong>Best for</strong>: Posters, logos, text-heavy designs</li>
<li><strong>Strengths</strong>: Exceptional typography, realistic outputs</li>
<li><strong>Use when</strong>: Text accuracy is critical</li>
<li><strong>Endpoint</strong>: <code>fal-ai/ideogram/v2</code></li>
</ul>
<h3><strong>bria/text-to-image/3.2</strong> (Commercial Safe)</h3>
<ul>
<li><strong>Best for</strong>: Commercial projects requiring licensed training data</li>
<li><strong>Strengths</strong>: Safe for commercial use, excellent text rendering</li>
<li><strong>Use when</strong>: Legal/licensing concerns matter</li>
<li><strong>Endpoint</strong>: <code>fal-ai/bria/text-to-image/3.2</code></li>
</ul>
<h2>Command-Line Interface</h2>
<pre><code class="language-bash">uv run python fal-text-to-image [OPTIONS] PROMPT

Arguments:
  PROMPT                    Text description of the image to generate

Options:
  -m, --model TEXT         Model to use (see model list above)
  -i, --image TEXT         Path or URL to reference image for style transfer
  -o, --output TEXT        Output filename (default: generated_image.png)
  -s, --size TEXT          Image size (e.g., &quot;1024x1024&quot;, &quot;landscape_16_9&quot;)
  --seed INTEGER           Random seed for reproducibility
  --steps INTEGER          Number of inference steps (model-dependent)
  --guidance FLOAT         Guidance scale (higher = more prompt adherence)
  --help                   Show this message and exit
</code></pre>
<h2>Authentication Setup</h2>
<p>Before first use, set your fal.ai API key:</p>
<pre><code class="language-bash">export FAL_KEY=&quot;your-api-key-here&quot;
</code></pre>
<p>Or create a <code>.env</code> file in the skill directory:</p>
<pre><code class="language-env">FAL_KEY=your-api-key-here
</code></pre>
<p>Get your API key from: <a href="https://fal.ai/dashboard/keys">https://fal.ai/dashboard/keys</a></p>
<h2>Advanced Examples</h2>
<h3>High-Resolution Professional Photo</h3>
<pre><code class="language-bash">uv run python fal-text-to-image \
  -m flux-pro/v1.1-ultra \
  &quot;Professional headshot of a business executive in modern office&quot; \
  -s 2048x2048
</code></pre>
<h3>Logo/Typography Design</h3>
<pre><code class="language-bash">uv run python fal-text-to-image \
  -m recraft/v3/text-to-image \
  &quot;Modern tech startup logo with text &#39;AI Labs&#39; in minimalist style&quot;
</code></pre>
<h3>Style Transfer from Reference</h3>
<pre><code class="language-bash">uv run python fal-text-to-image \
  -m flux-2/lora/edit \
  -i artistic_style.jpg \
  &quot;Portrait of a woman in a garden&quot;
</code></pre>
<h3>Reproducible Generation</h3>
<pre><code class="language-bash">uv run python fal-text-to-image \
  -m flux-2 \
  --seed 42 \
  &quot;Futuristic cityscape with flying cars&quot;
</code></pre>
<h2>Model Selection Logic</h2>
<p>The script automatically selects the best model when <code>-m</code> is not specified:</p>
<ol>
<li><strong>If <code>-i</code> provided</strong>: Uses <code>flux-2/lora/edit</code> for style transfer</li>
<li><strong>If prompt contains typography keywords</strong> (logo, text, poster, sign): Uses <code>recraft/v3/text-to-image</code></li>
<li><strong>If prompt suggests high-res needs</strong> (professional, portrait, headshot): Uses <code>flux-pro/v1.1-ultra</code></li>
<li><strong>If prompt mentions vector/brand</strong>: Uses <code>recraft/v3/text-to-image</code></li>
<li><strong>Default</strong>: Uses <code>flux-2</code> for general purpose</li>
</ol>
<h2>Output Format</h2>
<p>Generated images are saved with metadata:</p>
<ul>
<li>Filename includes timestamp and model name</li>
<li>EXIF data stores prompt, model, and parameters</li>
<li>Console displays generation time and cost estimate</li>
</ul>
<h2>Troubleshooting</h2>
<table>
<thead>
<tr>
<th>Problem</th>
<th>Solution</th>
</tr>
</thead>
<tbody><tr>
<td><code>FAL_KEY not set</code></td>
<td>Export FAL_KEY environment variable or create .env file</td>
</tr>
<tr>
<td><code>Model not found</code></td>
<td>Check model name against supported list</td>
</tr>
<tr>
<td><code>Image reference fails</code></td>
<td>Ensure image path/URL is accessible</td>
</tr>
<tr>
<td><code>Generation timeout</code></td>
<td>Some models take longer; wait or try faster model</td>
</tr>
<tr>
<td><code>Rate limit error</code></td>
<td>Check fal.ai dashboard for usage limits</td>
</tr>
</tbody></table>
<h2>Cost Optimization</h2>
<ul>
<li><strong>Free tier</strong>: FLUX.2 offers 100 free requests (expires Dec 25, 2025)</li>
<li><strong>Pay per use</strong>: FLUX Pro charges per megapixel</li>
<li><strong>Budget option</strong>: Use <code>flux-2</code> or <code>stable-diffusion-v35-large</code> for general use</li>
<li><strong>Premium</strong>: Use <code>flux-pro/v1.1-ultra</code> only when high-res is required</li>
</ul>
<h2>Image Remix: Model Selection Guide</h2>
<p>Available models for image-to-image remixing:</p>
<h3><strong>flux-2/dev</strong> (Default, Free)</h3>
<ul>
<li><strong>Best for</strong>: General remixing, style transfer, fast iteration</li>
<li><strong>Strengths</strong>: Balanced quality/speed, 100 free requests</li>
<li><strong>Use when</strong>: Standard remixing needs</li>
<li><strong>Endpoint</strong>: <code>fal-ai/flux/dev/image-to-image</code></li>
</ul>
<h3><strong>flux-pro</strong> (Premium Quality)</h3>
<ul>
<li><strong>Best for</strong>: Professional remixing, high-quality outputs</li>
<li><strong>Strengths</strong>: Superior quality, realistic transformations</li>
<li><strong>Use when</strong>: Professional or publication-ready remixes</li>
<li><strong>Endpoint</strong>: <code>fal-ai/flux-pro</code></li>
</ul>
<h3><strong>flux-1.1-pro</strong> (Ultra Premium)</h3>
<ul>
<li><strong>Best for</strong>: Highest quality remixing with maximum detail</li>
<li><strong>Strengths</strong>: Ultra-high quality, exceptional detail preservation</li>
<li><strong>Use when</strong>: Premium projects requiring best possible output</li>
<li><strong>Endpoint</strong>: <code>fal-ai/flux-pro/v1.1</code></li>
</ul>
<h3><strong>recraft/v3</strong> (Vector/Illustration)</h3>
<ul>
<li><strong>Best for</strong>: Vector style, brand imagery, illustration remixing</li>
<li><strong>Strengths</strong>: Clean vector outputs, brand-style transformations</li>
<li><strong>Use when</strong>: Converting to illustration or vector style</li>
<li><strong>Endpoint</strong>: <code>fal-ai/recraft/v3/text-to-image</code></li>
</ul>
<h3><strong>stable-diffusion-v35</strong> (Artistic)</h3>
<ul>
<li><strong>Best for</strong>: Artistic styles, painting effects, creative remixing</li>
<li><strong>Strengths</strong>: Strong artistic style application</li>
<li><strong>Use when</strong>: Artistic or stylized transformations</li>
<li><strong>Endpoint</strong>: <code>fal-ai/stable-diffusion-v35-large</code></li>
</ul>
<h2>Image Remix: Command-Line Interface</h2>
<pre><code class="language-bash">uv run python fal-image-remix [OPTIONS] INPUT_IMAGE PROMPT

Arguments:
  INPUT_IMAGE               Path or URL to source image
  PROMPT                    How to transform the image

Options:
  -m, --model TEXT         Model to use (auto-selected if not specified)
  -o, --output TEXT        Output filename (default: remixed_TIMESTAMP.png)
  -s, --strength FLOAT     Transformation strength 0.0-1.0 (default: 0.75)
                           0.0 = preserve original, 1.0 = full transformation
  --guidance FLOAT         Guidance scale (default: 7.5)
  --seed INTEGER           Random seed for reproducibility
  --steps INTEGER          Number of inference steps
  --help                   Show help
</code></pre>
<h3>Remix Strength Guide</h3>
<p>The <code>--strength</code> parameter controls transformation intensity:</p>
<table>
<thead>
<tr>
<th>Strength</th>
<th>Effect</th>
<th>Use Case</th>
</tr>
</thead>
<tbody><tr>
<td>0.3-0.5</td>
<td>Subtle changes</td>
<td>Minor color adjustments, lighting tweaks</td>
</tr>
<tr>
<td>0.5-0.7</td>
<td>Moderate changes</td>
<td>Style hints while preserving details</td>
</tr>
<tr>
<td>0.7-0.85</td>
<td>Strong changes</td>
<td>Clear style transfer, significant transformation</td>
</tr>
<tr>
<td>0.85-1.0</td>
<td>Maximum changes</td>
<td>Complete style overhaul, dramatic transformation</td>
</tr>
</tbody></table>
<h3>Remix Examples</h3>
<pre><code class="language-bash"># Subtle artistic style (low strength)
uv run python fal-image-remix photo.jpg &quot;Oil painting style&quot; --strength 0.4

# Balanced transformation (default)
uv run python fal-image-remix input.jpg &quot;Cyberpunk neon aesthetic&quot;

# Strong transformation (high strength)
uv run python fal-image-remix portrait.jpg &quot;Anime character&quot; --strength 0.9

# Vector conversion
uv run python fal-image-remix -m recraft/v3 logo.png &quot;Clean vector illustration&quot;

# Premium quality remix
uv run python fal-image-remix -m flux-1.1-pro photo.jpg &quot;Professional studio portrait&quot;
</code></pre>
<h2>Image Edit: Model Selection Guide</h2>
<p>Available models for targeted editing and inpainting:</p>
<h3><strong>flux-2/redux</strong> (General Editing)</h3>
<ul>
<li><strong>Best for</strong>: General image editing without masks</li>
<li><strong>Strengths</strong>: Fast, balanced, good for overall adjustments</li>
<li><strong>Use when</strong>: No specific region targeting needed</li>
<li><strong>Endpoint</strong>: <code>fal-ai/flux-2/redux</code></li>
</ul>
<h3><strong>flux-2/fill</strong> (Inpainting, Default)</h3>
<ul>
<li><strong>Best for</strong>: Masked region editing, object removal, filling</li>
<li><strong>Strengths</strong>: Seamless inpainting, natural blending</li>
<li><strong>Use when</strong>: Editing specific masked regions</li>
<li><strong>Endpoint</strong>: <code>fal-ai/flux-2/fill</code></li>
</ul>
<h3><strong>flux-pro-v11/fill</strong> (Premium Inpainting)</h3>
<ul>
<li><strong>Best for</strong>: Professional inpainting with highest quality</li>
<li><strong>Strengths</strong>: Superior quality, professional results</li>
<li><strong>Use when</strong>: Premium quality inpainting required</li>
<li><strong>Endpoint</strong>: <code>fal-ai/flux-pro-v11/fill</code></li>
</ul>
<h3><strong>stable-diffusion-v35/inpainting</strong> (Artistic Inpainting)</h3>
<ul>
<li><strong>Best for</strong>: Artistic edits, creative inpainting</li>
<li><strong>Strengths</strong>: Strong artistic control, detailed generation</li>
<li><strong>Use when</strong>: Artistic or stylized edits</li>
<li><strong>Endpoint</strong>: <code>fal-ai/stable-diffusion-v35-large/inpainting</code></li>
</ul>
<h3><strong>ideogram/v2/edit</strong> (Realistic Editing)</h3>
<ul>
<li><strong>Best for</strong>: Realistic modifications, precise edits</li>
<li><strong>Strengths</strong>: High realism, precise control</li>
<li><strong>Use when</strong>: Realistic edits required</li>
<li><strong>Endpoint</strong>: <code>fal-ai/ideogram/v2/edit</code></li>
</ul>
<h3><strong>recraft/v3/svg</strong> (Vector Editing)</h3>
<ul>
<li><strong>Best for</strong>: Vector style edits, clean illustrations</li>
<li><strong>Strengths</strong>: Clean vector outputs, illustration style</li>
<li><strong>Use when</strong>: Vector or illustration edits</li>
<li><strong>Endpoint</strong>: <code>fal-ai/recraft/v3/svg</code></li>
</ul>
<h2>Image Edit: Command-Line Interface</h2>
<pre><code class="language-bash">uv run python fal-image-edit [OPTIONS] INPUT_IMAGE [MASK_IMAGE] PROMPT

Arguments:
  INPUT_IMAGE               Path or URL to source image
  MASK_IMAGE                Path or URL to mask (white=edit, black=preserve) [optional]
  PROMPT                    How to edit the masked region

Options:
  -m, --model TEXT         Model to use (auto-selected if not specified)
  -o, --output TEXT        Output filename (default: edited_TIMESTAMP.png)
  --mask-prompt TEXT       Generate mask from text (no mask image needed)
  -s, --strength FLOAT     Edit strength 0.0-1.0 (default: 0.95)
  --guidance FLOAT         Guidance scale (default: 7.5)
  --seed INTEGER           Random seed for reproducibility
  --steps INTEGER          Number of inference steps
  --help                   Show help
</code></pre>
<h3>Edit Strength Guide</h3>
<p>The <code>--strength</code> parameter controls edit intensity:</p>
<table>
<thead>
<tr>
<th>Strength</th>
<th>Effect</th>
<th>Use Case</th>
</tr>
</thead>
<tbody><tr>
<td>0.5-0.7</td>
<td>Subtle edits</td>
<td>Minor touch-ups, color adjustments</td>
</tr>
<tr>
<td>0.7-0.9</td>
<td>Moderate edits</td>
<td>Clear modifications while blending naturally</td>
</tr>
<tr>
<td>0.9-1.0</td>
<td>Strong edits</td>
<td>Complete replacement, object removal</td>
</tr>
</tbody></table>
<h3>Creating Mask Images</h3>
<p>Mask images define edit regions:</p>
<ul>
<li><strong>White (255)</strong>: Areas to edit/modify</li>
<li><strong>Black (0)</strong>: Areas to preserve unchanged</li>
<li><strong>Gray</strong>: Partial blending (proportional to brightness)</li>
</ul>
<p>Create masks using:</p>
<ul>
<li>Image editors (GIMP, Photoshop, Krita)</li>
<li>Paint tools (select and fill with white/black)</li>
<li>Text-based prompts (<code>--mask-prompt</code> flag)</li>
</ul>
<h3>Edit Examples</h3>
<pre><code class="language-bash"># Edit with mask image
uv run python fal-image-edit photo.jpg mask.png &quot;Replace with beautiful garden&quot;

# Auto-generate mask from text
uv run python fal-image-edit landscape.jpg --mask-prompt &quot;sky&quot; &quot;Make it sunset with clouds&quot;

# Remove objects
uv run python fal-image-edit photo.jpg object_mask.png &quot;Remove completely&quot; --strength 1.0

# Seamless object insertion
uv run python fal-image-edit room.jpg region_mask.png &quot;Add modern sofa&quot; --strength 0.85

# General editing (no mask)
uv run python fal-image-edit -m flux-2/redux photo.jpg &quot;Enhance lighting and saturation&quot;

# Premium quality inpainting
uv run python fal-image-edit -m flux-pro-v11/fill image.jpg mask.png &quot;Professional portrait background&quot;

# Artistic modification
uv run python fal-image-edit -m stable-diffusion-v35/inpainting photo.jpg mask.png &quot;Van Gogh style&quot;
</code></pre>
<h2>File Structure</h2>
<pre><code>fal-text-to-image/
‚îú‚îÄ‚îÄ SKILL.md                    # This file
‚îú‚îÄ‚îÄ README.md                   # Quick reference
‚îú‚îÄ‚îÄ pyproject.toml              # Dependencies (uv)
‚îú‚îÄ‚îÄ fal-text-to-image           # Text-to-image generation script
‚îú‚îÄ‚îÄ fal-image-remix             # Image-to-image remixing script
‚îú‚îÄ‚îÄ fal-image-edit              # Image editing/inpainting script
‚îú‚îÄ‚îÄ references/
‚îÇ   ‚îî‚îÄ‚îÄ model-comparison.md     # Detailed model benchmarks
‚îî‚îÄ‚îÄ outputs/                    # Generated images (created on first run)
</code></pre>
<h2>Dependencies</h2>
<p>Managed via <code>uv</code>:</p>
<ul>
<li><code>fal-client</code>: Official fal.ai Python SDK</li>
<li><code>python-dotenv</code>: Environment variable management</li>
<li><code>pillow</code>: Image handling and EXIF metadata</li>
<li><code>click</code>: CLI interface</li>
</ul>
<h2>Best Practices</h2>
<h3>General</h3>
<ol>
<li><strong>Model Selection</strong>: Let scripts auto-select unless you have specific needs</li>
<li><strong>Prompt Engineering</strong>: Be specific and descriptive for better outputs</li>
<li><strong>Cost Awareness</strong>: Monitor usage on fal.ai dashboard</li>
<li><strong>Reproducibility</strong>: Use <code>--seed</code> for consistent results during iteration</li>
</ol>
<h3>Text-to-Image</h3>
<ol>
<li><strong>Reference Images</strong>: Use high-quality references for best style transfer results</li>
<li><strong>Size Selection</strong>: Match aspect ratio to intended use (square, landscape, portrait)</li>
<li><strong>Model Choice</strong>: Use recraft/v3 for typography, flux-pro for professional photography</li>
</ol>
<h3>Image Remix</h3>
<ol>
<li><strong>Strength Tuning</strong>: Start with default (0.75), adjust based on desired transformation</li>
<li><strong>Source Quality</strong>: Higher quality source images produce better remixes</li>
<li><strong>Iteration</strong>: Use --seed to iterate on same generation with different prompts</li>
<li><strong>Balance</strong>: Lower strength preserves more detail, higher creates more dramatic changes</li>
</ol>
<h3>Image Edit</h3>
<ol>
<li><strong>Mask Quality</strong>: Clean, well-defined masks produce better results</li>
<li><strong>Mask Creation</strong>: Use image editors for precise control, --mask-prompt for quick tests</li>
<li><strong>Blending</strong>: Use gray tones in masks for smooth transitions</li>
<li><strong>Edit Strength</strong>: Use 0.95+ for object removal, 0.7-0.9 for modifications</li>
<li><strong>Test First</strong>: Try --mask-prompt before creating detailed masks</li>
<li><strong>Multiple Edits</strong>: Edit in stages rather than all at once for complex modifications</li>
</ol>
<h2>Resources</h2>
<ul>
<li>fal.ai Documentation: <a href="https://docs.fal.ai/">https://docs.fal.ai/</a></li>
<li>Model Playground: <a href="https://fal.ai/explore/search">https://fal.ai/explore/search</a></li>
<li>API Keys: <a href="https://fal.ai/dashboard/keys">https://fal.ai/dashboard/keys</a></li>
<li>Pricing: <a href="https://fal.ai/pricing">https://fal.ai/pricing</a></li>
</ul>
<h2>Workflow Examples</h2>
<h3>Complete Image Creation Pipeline</h3>
<pre><code class="language-bash"># 1. Generate base image
uv run python fal-text-to-image -m flux-2 &quot;Modern office space, minimalist&quot; -o base.png

# 2. Remix to different style
uv run python fal-image-remix base.png &quot;Cyberpunk aesthetic with neon&quot; -o styled.png

# 3. Edit specific region
uv run python fal-image-edit styled.png --mask-prompt &quot;desk&quot; &quot;Add holographic display&quot;
</code></pre>
<h3>Iterative Refinement</h3>
<pre><code class="language-bash"># Generate with seed for reproducibility
uv run python fal-text-to-image &quot;Mountain landscape&quot; --seed 42 -o v1.png

# Remix with same seed, different style
uv run python fal-image-remix v1.png &quot;Oil painting style&quot; --seed 42 -o v2.png

# Fine-tune with editing
uv run python fal-image-edit v2.png --mask-prompt &quot;sky&quot; &quot;Golden hour lighting&quot; --seed 42
</code></pre>
<h3>Object Removal and Replacement</h3>
<pre><code class="language-bash"># 1. Remove unwanted object
uv run python fal-image-edit photo.jpg object_mask.png &quot;Remove&quot; --strength 1.0 -o removed.png

# 2. Fill with new content
uv run python fal-image-edit removed.png region_mask.png &quot;Beautiful flowers&quot; --strength 0.9
</code></pre>
<h2>Troubleshooting</h2>
<table>
<thead>
<tr>
<th>Problem</th>
<th>Solution</th>
<th>Tool</th>
</tr>
</thead>
<tbody><tr>
<td><code>FAL_KEY not set</code></td>
<td>Export FAL_KEY or create .env file</td>
<td>All</td>
</tr>
<tr>
<td><code>Model not found</code></td>
<td>Check model name in documentation</td>
<td>All</td>
</tr>
<tr>
<td><code>Image upload fails</code></td>
<td>Check file exists and is readable</td>
<td>Remix, Edit</td>
</tr>
<tr>
<td><code>Mask not working</code></td>
<td>Verify mask is grayscale PNG (white=edit)</td>
<td>Edit</td>
</tr>
<tr>
<td><code>Transformation too strong</code></td>
<td>Reduce --strength value</td>
<td>Remix, Edit</td>
</tr>
<tr>
<td><code>Transformation too weak</code></td>
<td>Increase --strength value</td>
<td>Remix, Edit</td>
</tr>
<tr>
<td><code>Mask-prompt not precise</code></td>
<td>Create manual mask in image editor</td>
<td>Edit</td>
</tr>
<tr>
<td><code>Generation timeout</code></td>
<td>Try faster model or wait longer</td>
<td>All</td>
</tr>
<tr>
<td><code>Rate limit error</code></td>
<td>Check fal.ai dashboard usage limits</td>
<td>All</td>
</tr>
</tbody></table>
<h2>Limitations</h2>
<h3>General</h3>
<ul>
<li>Requires active fal.ai API key</li>
<li>Subject to fal.ai rate limits and quotas</li>
<li>Internet connection required</li>
<li>Some models have usage costs (check pricing)</li>
</ul>
<h3>Text-to-Image</h3>
<ul>
<li>Image reference features limited to specific models</li>
<li>Typography quality varies by model</li>
</ul>
<h3>Image Remix</h3>
<ul>
<li>Source image quality affects output quality</li>
<li>Extreme strength values may introduce artifacts</li>
<li>Some styles work better with specific models</li>
</ul>
<h3>Image Edit</h3>
<ul>
<li>Mask quality critical for seamless results</li>
<li>Auto-generated masks (--mask-prompt) less precise than manual masks</li>
<li>Complex edits may require multiple passes</li>
<li>Some models don&#39;t support all editing features</li>
</ul>

                </div>
              </div>
            </article>
            <aside class="skill-page-sidebar">
              <div class="sidebar-card">
                <div class="sidebar-title">Actions</div>
                <a href="https://github.com/openclaw/skills/tree/main/skills/delorenj/fal-text-to-image/SKILL.md" target="_blank" rel="noopener" class="sidebar-btn sidebar-btn-primary">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/></svg>
                  View on GitHub
                </a>
                <a href="https://clawdhub.com/delorenj/fal-text-to-image" target="_blank" rel="noopener" class="sidebar-btn sidebar-btn-clawdhub">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"/><line x1="2" y1="12" x2="22" y2="12"/></svg>
                  View on ClawdHub
                </a>
                <a href="https://raw.githubusercontent.com/openclaw/skills/main/skills/delorenj/fal-text-to-image/SKILL.md" download="SKILL.md" class="sidebar-btn sidebar-btn-secondary">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/><polyline points="7 10 12 15 17 10"/><line x1="12" y1="15" x2="12" y2="3"/></svg>
                  Download SKILL.md
                </a>
                <button onclick="sendToSecurityAuditor()" class="sidebar-btn sidebar-btn-security">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 22s8-4 8-10V5l-8-3-8 3v7c0 6 8 10 8 10z"/></svg>
                  Security Check
                </button>
              </div>
              <div class="sidebar-card">
                <div class="sidebar-title">Details</div>
                <div class="sidebar-info">
                  <div class="sidebar-info-item">
                    <span class="sidebar-info-label">Author</span>
                    <span class="sidebar-info-value">@delorenj</span>
                  </div>
                  <div class="sidebar-info-item">
                    <span class="sidebar-info-label">Category</span>
                    <span class="sidebar-info-value">Image & Video Generation</span>
                  </div>
                </div>
              </div>
            </aside>
          </div>
        
  <footer class="footer">
    <div class="footer-inner">
      <p class="footer-text" style="margin-bottom: 8px;"><a href="https://github.com/neonone123/moltdirectory" target="_blank" rel="noopener" style="color: var(--accent); text-decoration: none;">View on GitHub</a></p>
      <p class="footer-text" style="opacity: 0.6; font-size: 13px;">OpenClawDirectory.com is a community-run project and is not affiliated with the official OpenClaw team or Peter Steinberger. We are just fans of the lobster.</p>
    </div>
  </footer>
  <script>
    function toggleTheme() {
      const html = document.documentElement;
      const currentTheme = html.getAttribute('data-theme');
      const newTheme = currentTheme === 'light' ? 'dark' : 'light';
      if (newTheme === 'light') {
        html.setAttribute('data-theme', 'light');
      } else {
        html.removeAttribute('data-theme');
      }
      localStorage.setItem('theme', newTheme);
    }
    
    function copySkillContent(btn) {
      const wrapper = btn.closest('.skill-source-wrapper');
      const content = wrapper.querySelector('.markdown-content');
      if (content) {
        const text = content.innerText || content.textContent;
        navigator.clipboard.writeText(text).then(() => {
          btn.classList.add('copied');
          btn.innerHTML = '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="20 6 9 17 4 12"/></svg> Copied!';
          setTimeout(() => {
            btn.classList.remove('copied');
            btn.innerHTML = '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"/><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"/></svg> Copy';
          }, 2000);
        });
      }
    }

    async function sendToSecurityAuditor() {
      try {
        const contentElement = document.querySelector('.markdown-content');
        if (!contentElement) throw new Error('Could not find markdown content');
        const skillContent = contentElement.innerText || contentElement.textContent;
        localStorage.setItem('skillAuditContent', skillContent);
        window.open('/security-auditor', '_blank'); 
      } catch (error) {
        alert('Error: ' + error.message);
      }
    }
  </script>
</body>
</html>