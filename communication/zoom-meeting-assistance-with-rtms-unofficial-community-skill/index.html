<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Zoom RTMS Meeting Assistant ‚Äî start on-demand to capture meeting audio, video, transcript, screenshare">
  <title>zoom-meeting-assistance-with-rtms-unofficial-community-skill - OpenClaw Directory</title>
  <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ü¶û</text></svg>">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../../style.css">
  <script>
    // Apply saved theme before page renders to prevent flash
    (function() {
      const savedTheme = localStorage.getItem('theme') || 'dark';
      if (savedTheme === 'light') {
        document.documentElement.setAttribute('data-theme', 'light');
      }
    })();
  </script>
</head>
<body>
  <header class="header">
    <div class="header-inner">
      <a href="../../index.html" class="logo">

        <span class="logo-text">OpenClaw Directory</span>
      </a>
      <nav class="header-links">
        <a href="../../start-here/index.html" class="header-link">Start Here</a>
        <a href="/security-auditor" class="header-link">Security Auditor</a>
        <a href="https://github.com/neonone123/moltdirectory/issues/new?template=add-skill.yml" class="header-link" target="_blank" rel="noopener">Add Skill</a>
        <button class="theme-toggle" aria-label="Toggle theme" onclick="toggleTheme()">
          <svg class="icon-moon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/></svg>
          <svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
        </button>
        <a href="https://www.reddit.com/r/OpenClawDirectory/" class="header-link" target="_blank" rel="noopener" aria-label="Community">
          <svg viewBox="0 0 16 16" fill="currentColor" width="28" height="28"><path d="M6.167 8a.83.83 0 0 0-.83.83c0 .459.372.84.83.831a.831.831 0 0 0 0-1.661m1.843 3.647c.315 0 1.403-.038 1.976-.611a.23.23 0 0 0 0-.306.213.213 0 0 0-.306 0c-.353.363-1.126.487-1.67.487-.545 0-1.308-.124-1.671-.487a.213.213 0 0 0-.306 0 .213.213 0 0 0 0 .306c.564.563 1.652.61 1.977.61zm.992-2.807c0 .458.373.83.831.83s.83-.381.83-.83a.831.831 0 0 0-1.66 0z"/><path d="M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0m-3.828-1.165c-.315 0-.602.124-.812.325-.801-.573-1.9-.945-3.121-.993l.534-2.501 1.738.372a.83.83 0 1 0 .83-.869.83.83 0 0 0-.744.468l-1.938-.41a.2.2 0 0 0-.153.028.2.2 0 0 0-.086.134l-.592 2.788c-1.24.038-2.358.41-3.17.992-.21-.2-.496-.324-.81-.324a1.163 1.163 0 0 0-.478 2.224q-.03.17-.029.353c0 1.795 2.091 3.256 4.669 3.256s4.668-1.451 4.668-3.256c0-.114-.01-.238-.029-.353.401-.181.688-.592.688-1.069 0-.65-.525-1.165-1.165-1.165"/></svg>
        </a>
      </nav>
    </div>
  </header>
  
          <section class="skill-page-header">
            <div class="skill-page-header-inner">
              <a href="../index.html" class="back-link">‚Üê Back to Communication</a>
              <div class="skill-page-meta">
                <a href="../index.html" class="skill-page-category">Communication</a>
                <span class="skill-page-author">by @tanchunsiong</span>
              </div>
              <h1 class="skill-page-title">zoom-meeting-assistance-with-rtms-unofficial-community-skill</h1>
              <p class="skill-page-desc">Zoom RTMS Meeting Assistant ‚Äî start on-demand to capture meeting audio, video, transcript, screenshare</p>
            </div>
          </section>
          <div class="skill-page-body">
            <article class="skill-page-content">
              <div class="skill-source-wrapper">
                <div class="skill-source-header">
                  <div class="skill-source-title">Source Code</div>
                  <button class="copy-btn" onclick="copySkillContent(this)">
                    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"/><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"/></svg>
                    Copy
                  </button>
                </div>
                <div class="markdown-content">
                  <h1>Zoom RTMS Meeting Assistant</h1>
<p>Headless capture service for Zoom meetings using Real-Time Media Streams (RTMS). Receives webhook events, connects to RTMS WebSockets, records all media, and runs AI analysis via OpenClaw.</p>
<h2>Webhook Events Handled</h2>
<p>This skill processes two Zoom webhook events:</p>
<ul>
<li><strong><code>meeting.rtms_started</code></strong> ‚Äî Zoom sends this when RTMS is activated for a meeting. Contains <code>server_urls</code>, <code>rtms_stream_id</code>, and <code>meeting_uuid</code> needed to connect to the RTMS WebSocket.</li>
<li><strong><code>meeting.rtms_stopped</code></strong> ‚Äî Zoom sends this when RTMS ends (meeting ended or RTMS disabled). Triggers cleanup: closes WebSocket connections, generates screenshare PDF, sends summary notification.</li>
</ul>
<h2>Webhook Dependency</h2>
<p>This skill needs a public webhook endpoint to receive these events from Zoom.</p>
<p><strong>Preferred:</strong> Use the <strong>ngrok-unofficial-webhook-skill</strong> (<code>skills/ngrok-unofficial-webhook-skill</code>). It auto-discovers this skill via <code>webhookEvents</code> in <code>skill.json</code>, notifies the user, and offers to route events here.</p>
<p>Other webhook solutions (e.g. custom servers, cloud functions) will work but require additional integration to forward payloads to this service.</p>
<h2>Prerequisites</h2>
<pre><code class="language-bash">cd skills/zoom-meeting-assistance-rtms-unofficial-community
npm install
</code></pre>
<p>Requires <code>ffmpeg</code> for post-meeting media conversion.</p>
<h2>Environment Variables</h2>
<p>Set these in the skill&#39;s <code>.env</code> file:</p>
<p><strong>Required:</strong></p>
<ul>
<li><code>ZOOM_SECRET_TOKEN</code> ‚Äî Zoom webhook secret token</li>
<li><code>ZOOM_CLIENT_ID</code> ‚Äî Zoom app Client ID</li>
<li><code>ZOOM_CLIENT_SECRET</code> ‚Äî Zoom app Client Secret</li>
</ul>
<p><strong>Optional:</strong></p>
<ul>
<li><code>PORT</code> ‚Äî Server port (default: <code>3000</code>)</li>
<li><code>AI_PROCESSING_INTERVAL_MS</code> ‚Äî AI analysis frequency in ms (default: <code>30000</code>)</li>
<li><code>AI_FUNCTION_STAGGER_MS</code> ‚Äî Delay between AI calls in ms (default: <code>5000</code>)</li>
<li><code>AUDIO_DATA_OPT</code> ‚Äî <code>1</code> = mixed stream, <code>2</code> = multi-stream (default: <code>2</code>)</li>
<li><code>OPENCLAW_NOTIFY_CHANNEL</code> ‚Äî Notification channel (default: <code>whatsapp</code>)</li>
<li><code>OPENCLAW_NOTIFY_TARGET</code> ‚Äî Phone number / target for notifications</li>
</ul>
<h2>Starting the Service</h2>
<pre><code class="language-bash">cd skills/zoom-meeting-assistance-rtms-unofficial-community
node index.js
</code></pre>
<p>This starts an Express server listening for Zoom webhook events on <code>PORT</code>.</p>
<p><strong>‚ö†Ô∏è Important:</strong> Before forwarding webhooks to this service, always check if it&#39;s running:</p>
<pre><code class="language-bash"># Check if service is listening on port 3000
lsof -i :3000
</code></pre>
<p>If nothing is returned, start the service first before forwarding any webhook events.</p>
<p><strong>Typical flow:</strong></p>
<ol>
<li>Start the server as a background process</li>
<li>Zoom sends <code>meeting.rtms_started</code> webhook ‚Üí service connects to RTMS WebSocket</li>
<li>Media streams in real-time: audio, video, transcript, screenshare, chat</li>
<li>AI processing runs periodically (dialog suggestions, sentiment, summary)</li>
<li><code>meeting.rtms_stopped</code> ‚Üí service closes connections, generates screenshare PDF</li>
</ol>
<h2>Recorded Data</h2>
<p>All recordings are stored organized by date:</p>
<pre><code>skills/zoom-meeting-assistance-rtms-unofficial-community/recordings/YYYY/MM/DD/{streamId}/
</code></pre>
<p>Each stream folder contains:</p>
<table>
<thead>
<tr>
<th>File</th>
<th>Content</th>
<th>Searchable</th>
</tr>
</thead>
<tbody><tr>
<td><code>metadata.json</code></td>
<td>Meeting metadata (UUID, stream ID, operator, start time)</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><code>transcript.txt</code></td>
<td>Plain text transcript with timestamps and speaker names</td>
<td>‚úÖ Best for searching ‚Äî grep-friendly, one line per utterance</td>
</tr>
<tr>
<td><code>transcript.vtt</code></td>
<td>VTT format transcript with timing cues</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><code>transcript.srt</code></td>
<td>SRT format transcript</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><code>events.log</code></td>
<td>Participant join/leave, active speaker changes (JSON lines)</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><code>chat.txt</code></td>
<td>Chat messages with timestamps</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><code>ai_summary.md</code></td>
<td>AI-generated meeting summary (markdown)</td>
<td>‚úÖ Key document ‚Äî read this first for meeting overview</td>
</tr>
<tr>
<td><code>ai_dialog.json</code></td>
<td>AI dialog suggestions</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><code>ai_sentiment.json</code></td>
<td>Sentiment analysis per participant</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><code>mixedaudio.raw</code></td>
<td>Mixed audio stream (raw PCM)</td>
<td>‚ùå Binary</td>
</tr>
<tr>
<td><code>activespeakervideo.h264</code></td>
<td>Active speaker video (raw H.264)</td>
<td>‚ùå Binary</td>
</tr>
<tr>
<td><code>processed/screenshare.pdf</code></td>
<td>Deduplicated screenshare frames as PDF</td>
<td>‚ùå Binary</td>
</tr>
</tbody></table>
<p>All summaries are also copied to a central folder for easy access:</p>
<pre><code>skills/zoom-meeting-assistance-rtms-unofficial-community/summaries/summary_YYYY-MM-DDTHH-MM-SS_{streamId}.md
</code></pre>
<h2>Searching &amp; Querying Past Meetings</h2>
<p>To find and review past meeting data:</p>
<pre><code class="language-bash"># List all recorded meetings by date
ls -R recordings/

# List meetings for a specific date
ls recordings/2026/01/28/

# Search across all transcripts for a keyword
grep -rl &quot;keyword&quot; recordings/*/*/*/*/transcript.txt

# Search for what a specific person said
grep &quot;Chun Siong Tan&quot; recordings/*/*/*/*/transcript.txt

# Read a meeting summary
cat recordings/YYYY/MM/DD/&lt;streamId&gt;/ai_summary.md

# Search summaries for a topic
grep -rl &quot;topic&quot; recordings/*/*/*/*/ai_summary.md

# Check who attended a meeting
cat recordings/YYYY/MM/DD/&lt;streamId&gt;/events.log

# Get sentiment for a meeting
cat recordings/YYYY/MM/DD/&lt;streamId&gt;/ai_sentiment.json
</code></pre>
<p>The <code>.txt</code>, <code>.md</code>, <code>.json</code>, and <code>.log</code> files are all text-based and searchable. Start with <code>ai_summary.md</code> for a quick overview, then drill into <code>transcript.txt</code> for specific quotes or details.</p>
<h2>API Endpoints</h2>
<pre><code class="language-bash"># Toggle WhatsApp notifications on/off
curl -X POST http://localhost:3000/api/notify-toggle -H &quot;Content-Type: application/json&quot; -d &#39;{&quot;enabled&quot;: false}&#39;

# Check notification status
curl http://localhost:3000/api/notify-toggle
</code></pre>
<h2>Post-Meeting Processing</h2>
<p>When <code>meeting.rtms_stopped</code> fires, the service automatically:</p>
<ol>
<li>Generates PDF from screenshare images</li>
<li>Converts <code>mixedaudio.raw</code> ‚Üí <code>mixedaudio.wav</code></li>
<li>Converts <code>activespeakervideo.h264</code> ‚Üí <code>activespeakervideo.mp4</code></li>
<li>Muxes mixed audio + active speaker video into <code>final_output.mp4</code></li>
</ol>
<p>Manual conversion scripts are available but note that auto-conversion runs on meeting end, so manual re-runs are rarely needed.</p>
<h2>Reading Meeting Data</h2>
<p>After or during a meeting, read files from <code>recordings/YYYY/MM/DD/{streamId}/</code>:</p>
<pre><code class="language-bash"># List recorded meetings by date
ls -R recordings/

# Read transcript
cat recordings/YYYY/MM/DD/&lt;streamId&gt;/transcript.txt

# Read AI summary
cat recordings/YYYY/MM/DD/&lt;streamId&gt;/ai_summary.md

# Read sentiment analysis
cat recordings/YYYY/MM/DD/&lt;streamId&gt;/ai_sentiment.json
</code></pre>
<h2>Prompt Customization</h2>
<p>Want different summary styles or analysis? Customize the AI prompts to fit your needs!</p>
<p>Edit these files to change AI behavior:</p>
<table>
<thead>
<tr>
<th>File</th>
<th>Purpose</th>
<th>Example Customizations</th>
</tr>
</thead>
<tbody><tr>
<td><code>summary_prompt.md</code></td>
<td>Meeting summary generation</td>
<td>Bullet points vs prose, focus areas, length</td>
</tr>
<tr>
<td><code>query_prompt.md</code></td>
<td>Query response formatting</td>
<td>Response style, detail level</td>
</tr>
<tr>
<td><code>query_prompt_current_meeting.md</code></td>
<td>Real-time meeting analysis</td>
<td>What to highlight during meetings</td>
</tr>
<tr>
<td><code>query_prompt_dialog_suggestions.md</code></td>
<td>Dialog suggestion style</td>
<td>Formal vs casual, suggestion count</td>
</tr>
<tr>
<td><code>query_prompt_sentiment_analysis.md</code></td>
<td>Sentiment scoring logic</td>
<td>Custom sentiment categories, thresholds</td>
</tr>
</tbody></table>
<p><strong>Tip:</strong> Back up the originals before editing, so you can revert if needed.</p>

                </div>
              </div>
            </article>
            <aside class="skill-page-sidebar">
              <div class="sidebar-card">
                <div class="sidebar-title">Actions</div>
                <a href="https://github.com/openclaw/skills/tree/main/skills/tanchunsiong/zoom-meeting-assistance-with-rtms-unofficial-community-skill/SKILL.md" target="_blank" rel="noopener" class="sidebar-btn sidebar-btn-primary">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/></svg>
                  View on GitHub
                </a>
                <a href="https://clawdhub.com/tanchunsiong/zoom-meeting-assistance-with-rtms-unofficial-community-skill" target="_blank" rel="noopener" class="sidebar-btn sidebar-btn-clawdhub">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"/><line x1="2" y1="12" x2="22" y2="12"/></svg>
                  View on ClawdHub
                </a>
                <a href="https://raw.githubusercontent.com/openclaw/skills/main/skills/tanchunsiong/zoom-meeting-assistance-with-rtms-unofficial-community-skill/SKILL.md" download="SKILL.md" class="sidebar-btn sidebar-btn-secondary">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/><polyline points="7 10 12 15 17 10"/><line x1="12" y1="15" x2="12" y2="3"/></svg>
                  Download SKILL.md
                </a>
                <button onclick="sendToSecurityAuditor()" class="sidebar-btn sidebar-btn-security">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 22s8-4 8-10V5l-8-3-8 3v7c0 6 8 10 8 10z"/></svg>
                  Security Check
                </button>
              </div>
              <div class="sidebar-card">
                <div class="sidebar-title">Details</div>
                <div class="sidebar-info">
                  <div class="sidebar-info-item">
                    <span class="sidebar-info-label">Author</span>
                    <span class="sidebar-info-value">@tanchunsiong</span>
                  </div>
                  <div class="sidebar-info-item">
                    <span class="sidebar-info-label">Category</span>
                    <span class="sidebar-info-value">Communication</span>
                  </div>
                </div>
              </div>
            </aside>
          </div>
        
  <footer class="footer">
    <div class="footer-inner">
      <p class="footer-text" style="margin-bottom: 8px;"><a href="https://github.com/neonone123/moltdirectory" target="_blank" rel="noopener" style="color: var(--accent); text-decoration: none;">View on GitHub</a></p>
      <p class="footer-text" style="opacity: 0.6; font-size: 13px;">OpenClawDirectory.com is a community-run project and is not affiliated with the official OpenClaw team or Peter Steinberger. We are just fans of the lobster.</p>
    </div>
  </footer>
  <script>
    function toggleTheme() {
      const html = document.documentElement;
      const currentTheme = html.getAttribute('data-theme');
      const newTheme = currentTheme === 'light' ? 'dark' : 'light';
      if (newTheme === 'light') {
        html.setAttribute('data-theme', 'light');
      } else {
        html.removeAttribute('data-theme');
      }
      localStorage.setItem('theme', newTheme);
    }
    
    function copySkillContent(btn) {
      const wrapper = btn.closest('.skill-source-wrapper');
      const content = wrapper.querySelector('.markdown-content');
      if (content) {
        const text = content.innerText || content.textContent;
        navigator.clipboard.writeText(text).then(() => {
          btn.classList.add('copied');
          btn.innerHTML = '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="20 6 9 17 4 12"/></svg> Copied!';
          setTimeout(() => {
            btn.classList.remove('copied');
            btn.innerHTML = '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"/><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"/></svg> Copy';
          }, 2000);
        });
      }
    }

    async function sendToSecurityAuditor() {
      try {
        const contentElement = document.querySelector('.markdown-content');
        if (!contentElement) throw new Error('Could not find markdown content');
        const skillContent = contentElement.innerText || contentElement.textContent;
        localStorage.setItem('skillAuditContent', skillContent);
        window.open('/security-auditor', '_blank'); 
      } catch (error) {
        alert('Error: ' + error.message);
      }
    }
  </script>
</body>
</html>