<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Parse, search, and analyze application logs">
  <title>log-analyzer - OpenClaw Directory</title>
  <link rel="canonical" href="https://moltdirectory.com/devops-cloud/log-analyzer/">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ü¶û</text></svg>">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/style.css">
  <script>
    // Apply saved theme before page renders to prevent flash
    (function() {
      const savedTheme = localStorage.getItem('theme') || 'dark';
      if (savedTheme === 'light') {
        document.documentElement.setAttribute('data-theme', 'light');
      }
    })();
  </script>
</head>
<body>
  <header class="header">
    <div class="header-inner">
      <a href="/" class="logo">

        <span class="logo-text">OpenClaw Directory</span>
      </a>
      <nav class="header-links">
        <a href="/start-here/" class="header-link">Start Here</a>
        <a href="/security-auditor" class="header-link">Security Auditor</a>
        <a href="https://github.com/neonone123/moltdirectory/issues/new?template=add-skill.yml" class="header-link" target="_blank" rel="noopener">Add Skill</a>
        <button class="theme-toggle" aria-label="Toggle theme" onclick="toggleTheme()">
          <svg class="icon-moon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/></svg>
          <svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
        </button>
        <a href="https://www.reddit.com/r/OpenClawDirectory/" class="header-link" target="_blank" rel="noopener" aria-label="Community">
          <svg viewBox="0 0 16 16" fill="currentColor" width="28" height="28"><path d="M6.167 8a.83.83 0 0 0-.83.83c0 .459.372.84.83.831a.831.831 0 0 0 0-1.661m1.843 3.647c.315 0 1.403-.038 1.976-.611a.23.23 0 0 0 0-.306.213.213 0 0 0-.306 0c-.353.363-1.126.487-1.67.487-.545 0-1.308-.124-1.671-.487a.213.213 0 0 0-.306 0 .213.213 0 0 0 0 .306c.564.563 1.652.61 1.977.61zm.992-2.807c0 .458.373.83.831.83s.83-.381.83-.83a.831.831 0 0 0-1.66 0z"/><path d="M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0m-3.828-1.165c-.315 0-.602.124-.812.325-.801-.573-1.9-.945-3.121-.993l.534-2.501 1.738.372a.83.83 0 1 0 .83-.869.83.83 0 0 0-.744.468l-1.938-.41a.2.2 0 0 0-.153.028.2.2 0 0 0-.086.134l-.592 2.788c-1.24.038-2.358.41-3.17.992-.21-.2-.496-.324-.81-.324a1.163 1.163 0 0 0-.478 2.224q-.03.17-.029.353c0 1.795 2.091 3.256 4.669 3.256s4.668-1.451 4.668-3.256c0-.114-.01-.238-.029-.353.401-.181.688-.592.688-1.069 0-.65-.525-1.165-1.165-1.165"/></svg>
        </a>
      </nav>
    </div>
  </header>
  
          <section class="skill-page-header">
            <div class="skill-page-header-inner">
              <a href="/devops-cloud/" class="back-link">‚Üê Back to DevOps & Cloud</a>
              <div class="skill-page-meta">
                <a href="/devops-cloud/" class="skill-page-category">DevOps & Cloud</a>
                <span class="skill-page-author">by @gitgoodordietrying</span>
              </div>
              <h1 class="skill-page-title">log-analyzer</h1>
              <p class="skill-page-desc">Parse, search, and analyze application logs</p>
              <div class="vote-widget skill-page-vote" data-category-id="devops-cloud" data-tool-id="log-analyzer">
                <button type="button" class="vote-btn" data-vote="1" aria-label="Upvote log-analyzer">‚ñ≤</button>
                <span class="vote-count">New</span>
                <button type="button" class="vote-btn" data-vote="-1" aria-label="Downvote log-analyzer">‚ñº</button>
              </div>
            </div>
          </section>
          <div class="skill-page-body">
            <article class="skill-page-content">
              <div class="skill-source-wrapper">
                <div class="skill-source-header">
                  <div class="skill-source-title">Source Code</div>
                  <button class="copy-btn" onclick="copySkillContent(this)">
                    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"/><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"/></svg>
                    Copy
                  </button>
                </div>
                <div class="markdown-content">
                  <h1>Log Analyzer</h1>
<p>Parse, search, and debug from application logs. Covers plain text logs, structured JSON logs, stack traces, multi-service correlation, and real-time monitoring.</p>
<h2>When to Use</h2>
<ul>
<li>Debugging application errors from log files</li>
<li>Searching logs for specific patterns, errors, or request IDs</li>
<li>Parsing and analyzing stack traces</li>
<li>Setting up structured logging (JSON) in applications</li>
<li>Correlating events across multiple services or log files</li>
<li>Monitoring logs in real time during development</li>
<li>Generating error frequency reports or summaries</li>
</ul>
<h2>Quick Search Patterns</h2>
<h3>Find errors and exceptions</h3>
<pre><code class="language-bash"># All errors in a log file
grep -i &#39;error\|exception\|fatal\|panic\|fail&#39; app.log

# Errors with 3 lines of context
grep -i -C 3 &#39;error\|exception&#39; app.log

# Errors in the last hour (ISO timestamps)
HOUR_AGO=$(date -u -d &#39;1 hour ago&#39; &#39;+%Y-%m-%dT%H:%M&#39; 2&gt;/dev/null || date -u -v-1H &#39;+%Y-%m-%dT%H:%M&#39;)
awk -v t=&quot;$HOUR_AGO&quot; &#39;$0 ~ /^[0-9]{4}-[0-9]{2}-[0-9]{2}T/ &amp;&amp; $1 &gt;= t&#39; app.log | grep -i &#39;error&#39;

# Count errors by type
grep -oP &#39;(?:Error|Exception): \K[^\n]+&#39; app.log | sort | uniq -c | sort -rn | head -20

# HTTP 5xx errors from access logs
awk &#39;$9 &gt;= 500&#39; access.log
</code></pre>
<h3>Search by request or correlation ID</h3>
<pre><code class="language-bash"># Trace a single request across log entries
grep &#39;req-abc123&#39; app.log

# Across multiple files
grep -r &#39;req-abc123&#39; /var/log/myapp/

# Across multiple services (with filename prefix)
grep -rH &#39;correlation-id-xyz&#39; /var/log/service-a/ /var/log/service-b/ /var/log/service-c/
</code></pre>
<h3>Time-range filtering</h3>
<pre><code class="language-bash"># Between two timestamps (ISO format)
awk &#39;$0 &gt;= &quot;2026-02-03T10:00&quot; &amp;&amp; $0 &lt;= &quot;2026-02-03T11:00&quot;&#39; app.log

# Last N lines (tail)
tail -1000 app.log | grep -i error

# Since a specific time (GNU date)
awk -v start=&quot;$(date -d &#39;30 minutes ago&#39; &#39;+%Y-%m-%dT%H:%M&#39;)&quot; &#39;$1 &gt;= start&#39; app.log
</code></pre>
<h2>JSON / Structured Logs</h2>
<h3>Parse with jq</h3>
<pre><code class="language-bash"># Pretty-print JSON logs
cat app.log | jq &#39;.&#39;

# Filter by level
cat app.log | jq &#39;select(.level == &quot;error&quot;)&#39;

# Filter by time range
cat app.log | jq &#39;select(.timestamp &gt;= &quot;2026-02-03T10:00:00Z&quot;)&#39;

# Extract specific fields
cat app.log | jq -r &#39;[.timestamp, .level, .message] | @tsv&#39;

# Count by level
cat app.log | jq -r &#39;.level&#39; | sort | uniq -c | sort -rn

# Filter by nested field
cat app.log | jq &#39;select(.context.userId == &quot;user-123&quot;)&#39;

# Group errors by message
cat app.log | jq -r &#39;select(.level == &quot;error&quot;) | .message&#39; | sort | uniq -c | sort -rn

# Extract request duration stats
cat app.log | jq -r &#39;select(.duration != null) | .duration&#39; | awk &#39;{sum+=$1; count++; if($1&gt;max)max=$1} END {print &quot;count=&quot;count, &quot;avg=&quot;sum/count, &quot;max=&quot;max}&#39;
</code></pre>
<h3>Parse mixed-format logs (JSON lines mixed with plain text)</h3>
<pre><code class="language-bash"># Extract only valid JSON lines
while IFS= read -r line; do
  echo &quot;$line&quot; | jq &#39;.&#39; 2&gt;/dev/null &amp;&amp; continue
done &lt; app.log

# Or with grep for lines starting with {
grep &#39;^\s*{&#39; app.log | jq &#39;.&#39;
</code></pre>
<h2>Stack Trace Analysis</h2>
<h3>Extract and deduplicate stack traces</h3>
<pre><code class="language-bash"># Extract Java/Kotlin stack traces (starts with Exception/Error, followed by \tat lines)
awk &#39;/Exception|Error/{trace=$0; while(getline &amp;&amp; /^\t/) trace=trace&quot;\n&quot;$0; print trace&quot;\n---&quot;}&#39; app.log

# Extract Python tracebacks
awk &#39;/^Traceback/{p=1} p{print} /^[A-Za-z].*Error/{if(p) print &quot;---&quot;; p=0}&#39; app.log

# Extract Node.js stack traces (Error + indented &quot;at&quot; lines)
awk &#39;/Error:/{trace=$0; while(getline &amp;&amp; /^    at /) trace=trace&quot;\n&quot;$0; print trace&quot;\n---&quot;}&#39; app.log

# Deduplicate: group by root cause (first line of trace)
awk &#39;/Exception|Error:/{cause=$0} /^\tat|^    at /{next} cause{print cause; cause=&quot;&quot;}&#39; app.log | sort | uniq -c | sort -rn
</code></pre>
<h3>Python traceback parser</h3>
<pre><code class="language-python">#!/usr/bin/env python3
&quot;&quot;&quot;Parse Python tracebacks from log files and group by root cause.&quot;&quot;&quot;
import sys
import re
from collections import Counter

def extract_tracebacks(filepath):
    tracebacks = []
    current = []
    in_trace = False

    with open(filepath) as f:
        for line in f:
            if line.startswith(&#39;Traceback (most recent call last):&#39;):
                in_trace = True
                current = [line.rstrip()]
            elif in_trace:
                current.append(line.rstrip())
                # Exception line ends the traceback
                if re.match(r&#39;^[A-Za-z]\w*(Error|Exception|Warning)&#39;, line):
                    tracebacks.append(&#39;\n&#39;.join(current))
                    in_trace = False
                    current = []
    return tracebacks

if __name__ == &#39;__main__&#39;:
    filepath = sys.argv[1] if len(sys.argv) &gt; 1 else &#39;/dev/stdin&#39;
    traces = extract_tracebacks(filepath)

    # Group by exception type and message
    causes = Counter()
    for trace in traces:
        lines = trace.split(&#39;\n&#39;)
        cause = lines[-1] if lines else &#39;Unknown&#39;
        causes[cause] += 1

    print(f&quot;Found {len(traces)} tracebacks, {len(causes)} unique causes:\n&quot;)
    for cause, count in causes.most_common(20):
        print(f&quot;  {count:4d}x  {cause}&quot;)
</code></pre>
<h2>Real-Time Monitoring</h2>
<h3>Tail and filter</h3>
<pre><code class="language-bash"># Follow log file, highlight errors in red
tail -f app.log | grep --color=always -i &#39;error\|warn\|$&#39;

# Follow and filter to errors only
tail -f app.log | grep --line-buffered -i &#39;error\|exception&#39;

# Follow JSON logs, pretty-print errors
tail -f app.log | while IFS= read -r line; do
  level=$(echo &quot;$line&quot; | jq -r &#39;.level // empty&#39; 2&gt;/dev/null)
  if [ &quot;$level&quot; = &quot;error&quot; ] || [ &quot;$level&quot; = &quot;fatal&quot; ]; then
    echo &quot;$line&quot; | jq &#39;.&#39;
  fi
done

# Follow multiple files
tail -f /var/log/service-a/app.log /var/log/service-b/app.log

# Follow with timestamps (useful when log doesn&#39;t include them)
tail -f app.log | while IFS= read -r line; do
  echo &quot;$(date &#39;+%H:%M:%S&#39;) $line&quot;
done
</code></pre>
<h3>Watch for specific patterns and alert</h3>
<pre><code class="language-bash"># Beep on error (terminal bell)
tail -f app.log | grep --line-buffered -i &#39;error&#39; | while read line; do
  echo -e &quot;\a$line&quot;
done

# Count errors per minute
tail -f app.log | grep --line-buffered -i &#39;error&#39; | while read line; do
  echo &quot;$(date &#39;+%Y-%m-%d %H:%M&#39;) ERROR&quot;
done | uniq -c
</code></pre>
<h2>Log Format Parsing</h2>
<h3>Common access log (Apache/Nginx)</h3>
<pre><code class="language-bash"># Parse fields: IP, date, method, path, status, size
awk &#39;{print $1, $9, $7}&#39; access.log

# Top IPs by request count
awk &#39;{print $1}&#39; access.log | sort | uniq -c | sort -rn | head -20

# Top paths by request count
awk &#39;{print $7}&#39; access.log | sort | uniq -c | sort -rn | head -20

# Slow requests (response time in last field, microseconds)
awk &#39;{if ($NF &gt; 1000000) print $0}&#39; access.log

# Requests per minute
awk &#39;{split($4,a,&quot;:&quot;); print a[1]&quot;:&quot;a[2]&quot;:&quot;a[3]}&#39; access.log | uniq -c

# Status code distribution
awk &#39;{print $9}&#39; access.log | sort | uniq -c | sort -rn

# 4xx and 5xx with paths
awk &#39;$9 &gt;= 400 {print $9, $7}&#39; access.log | sort | uniq -c | sort -rn | head -20
</code></pre>
<h3>Custom delimited logs</h3>
<pre><code class="language-bash"># Pipe-delimited: timestamp|level|service|message
awk -F&#39;|&#39; &#39;{print $2, $3, $4}&#39; app.log

# Tab-delimited
awk -F&#39;\t&#39; &#39;$2 == &quot;ERROR&quot; {print $1, $4}&#39; app.log

# CSV logs
python3 -c &quot;
import csv, sys
with open(sys.argv[1]) as f:
    for row in csv.DictReader(f):
        if row.get(&#39;level&#39;) == &#39;error&#39;:
            print(f\&quot;{row[&#39;timestamp&#39;]} {row[&#39;message&#39;]}\&quot;)
&quot; app.csv
</code></pre>
<h2>Setting Up Structured Logging</h2>
<h3>Node.js (pino ‚Äî fast JSON logger)</h3>
<pre><code class="language-javascript">// npm install pino
const pino = require(&#39;pino&#39;);
const logger = pino({
  level: process.env.LOG_LEVEL || &#39;info&#39;,
  // Add standard fields to every log line
  base: { service: &#39;my-api&#39;, version: &#39;1.2.0&#39; },
});

// Usage
logger.info({ userId: &#39;u123&#39;, action: &#39;login&#39; }, &#39;User logged in&#39;);
logger.error({ err, requestId: req.id }, &#39;Request failed&#39;);

// Output: {&quot;level&quot;:30,&quot;time&quot;:1706900000000,&quot;service&quot;:&quot;my-api&quot;,&quot;userId&quot;:&quot;u123&quot;,&quot;action&quot;:&quot;login&quot;,&quot;msg&quot;:&quot;User logged in&quot;}

// Child logger with bound context
const reqLogger = logger.child({ requestId: req.id, userId: req.user?.id });
reqLogger.info(&#39;Processing order&#39;);
reqLogger.error({ err }, &#39;Order failed&#39;);
</code></pre>
<h3>Python (structlog)</h3>
<pre><code class="language-python"># pip install structlog
import structlog

structlog.configure(
    processors=[
        structlog.processors.TimeStamper(fmt=&quot;iso&quot;),
        structlog.processors.add_log_level,
        structlog.processors.JSONRenderer(),
    ],
)
logger = structlog.get_logger(service=&quot;my-api&quot;)

# Usage
logger.info(&quot;user_login&quot;, user_id=&quot;u123&quot;, ip=&quot;1.2.3.4&quot;)
logger.error(&quot;request_failed&quot;, request_id=&quot;req-abc&quot;, error=str(e))

# Output: {&quot;event&quot;:&quot;user_login&quot;,&quot;user_id&quot;:&quot;u123&quot;,&quot;ip&quot;:&quot;1.2.3.4&quot;,&quot;level&quot;:&quot;info&quot;,&quot;timestamp&quot;:&quot;2026-02-03T12:00:00Z&quot;,&quot;service&quot;:&quot;my-api&quot;}
</code></pre>
<h3>Go (zerolog)</h3>
<pre><code class="language-go">import (
    &quot;os&quot;
    &quot;github.com/rs/zerolog&quot;
    &quot;github.com/rs/zerolog/log&quot;
)

func init() {
    zerolog.TimeFieldFormat = zerolog.TimeFormatUnix
    log.Logger = zerolog.New(os.Stdout).With().
        Timestamp().
        Str(&quot;service&quot;, &quot;my-api&quot;).
        Logger()
}

// Usage
log.Info().Str(&quot;userId&quot;, &quot;u123&quot;).Msg(&quot;User logged in&quot;)
log.Error().Err(err).Str(&quot;requestId&quot;, reqID).Msg(&quot;Request failed&quot;)
</code></pre>
<h2>Error Pattern Reports</h2>
<h3>Generate error frequency report</h3>
<pre><code class="language-bash">#!/bin/bash
# error-report.sh - Summarize errors from a log file
LOG=&quot;${1:?Usage: error-report.sh &lt;logfile&gt;}&quot;

echo &quot;=== Error Report: $(basename &quot;$LOG&quot;) ===&quot;
echo &quot;Generated: $(date -u &#39;+%Y-%m-%dT%H:%M:%SZ&#39;)&quot;
echo &quot;&quot;

total=$(wc -l &lt; &quot;$LOG&quot;)
errors=$(grep -ci &#39;error\|exception\|fatal&#39; &quot;$LOG&quot;)
warns=$(grep -ci &#39;warn&#39; &quot;$LOG&quot;)

echo &quot;Total lines:  $total&quot;
echo &quot;Errors:       $errors&quot;
echo &quot;Warnings:     $warns&quot;
echo &quot;&quot;

echo &quot;--- Top 15 Error Messages ---&quot;
grep -i &#39;error\|exception&#39; &quot;$LOG&quot; | \
  sed &#39;s/^[0-9TZ:.+\-]* //&#39; | \
  sed &#39;s/\b[0-9a-f]\{8,\}\b/ID/g&#39; | \
  sed &#39;s/[0-9]\{1,\}/N/g&#39; | \
  sort | uniq -c | sort -rn | head -15
echo &quot;&quot;

echo &quot;--- Errors Per Hour ---&quot;
grep -i &#39;error\|exception&#39; &quot;$LOG&quot; | \
  grep -oP &#39;\d{4}-\d{2}-\d{2}T\d{2}&#39; | \
  sort | uniq -c
echo &quot;&quot;

echo &quot;--- First Occurrence of Each Error Type ---&quot;
grep -i &#39;error\|exception&#39; &quot;$LOG&quot; | \
  sed &#39;s/^[0-9TZ:.+\-]* //&#39; | \
  sort -u | head -10
</code></pre>
<h3>JSON log error report with Python</h3>
<pre><code class="language-python">#!/usr/bin/env python3
&quot;&quot;&quot;Generate error summary from JSON log files.&quot;&quot;&quot;
import json
import sys
from collections import Counter, defaultdict
from datetime import datetime

def analyze_logs(filepath):
    errors = []
    levels = Counter()
    errors_by_hour = defaultdict(int)

    with open(filepath) as f:
        for line in f:
            try:
                entry = json.loads(line.strip())
            except (json.JSONDecodeError, ValueError):
                continue

            level = entry.get(&#39;level&#39;, entry.get(&#39;severity&#39;, &#39;&#39;)).lower()
            levels[level] += 1

            if level in (&#39;error&#39;, &#39;fatal&#39;, &#39;critical&#39;):
                msg = entry.get(&#39;message&#39;, entry.get(&#39;msg&#39;, entry.get(&#39;event&#39;, &#39;unknown&#39;)))
                ts = entry.get(&#39;timestamp&#39;, entry.get(&#39;time&#39;, &#39;&#39;))
                errors.append({&#39;message&#39;: msg, &#39;timestamp&#39;: ts, &#39;entry&#39;: entry})

                # Group by hour
                try:
                    hour = ts[:13]  # &quot;2026-02-03T12&quot;
                    errors_by_hour[hour] += 1
                except (TypeError, IndexError):
                    pass

    # Group errors by message
    error_counts = Counter(e[&#39;message&#39;] for e in errors)

    print(f&quot;=== Log Analysis: {filepath} ===\n&quot;)
    print(&quot;Level distribution:&quot;)
    for level, count in levels.most_common():
        print(f&quot;  {level:10s}  {count}&quot;)

    print(f&quot;\nTotal errors: {len(errors)}&quot;)
    print(f&quot;Unique error messages: {len(error_counts)}\n&quot;)

    print(&quot;Top 15 errors:&quot;)
    for msg, count in error_counts.most_common(15):
        print(f&quot;  {count:4d}x  {msg[:100]}&quot;)

    if errors_by_hour:
        print(&quot;\nErrors by hour:&quot;)
        for hour in sorted(errors_by_hour):
            bar = &#39;#&#39; * min(errors_by_hour[hour], 50)
            print(f&quot;  {hour}  {errors_by_hour[hour]:4d}  {bar}&quot;)

if __name__ == &#39;__main__&#39;:
    analyze_logs(sys.argv[1])
</code></pre>
<h2>Multi-Service Log Correlation</h2>
<h3>Merge and sort logs from multiple services</h3>
<pre><code class="language-bash"># Merge multiple log files, sort by timestamp
sort -m -t&#39;T&#39; -k1,1 service-a.log service-b.log service-c.log &gt; merged.log

# If files aren&#39;t individually sorted, use full sort
sort -t&#39;T&#39; -k1,1 service-*.log &gt; merged.log

# Merge JSON logs, add source field
for f in service-*.log; do
  service=$(basename &quot;$f&quot; .log)
  jq --arg svc &quot;$service&quot; &#39;. + {source: $svc}&#39; &quot;$f&quot;
done | jq -s &#39;sort_by(.timestamp)[]&#39;
</code></pre>
<h3>Trace a request across services</h3>
<pre><code class="language-bash"># Find all log entries for a correlation/request ID across all services
REQUEST_ID=&quot;req-abc-123&quot;
grep -rH &quot;$REQUEST_ID&quot; /var/log/services/ | sort -t: -k2

# With JSON logs
for f in /var/log/services/*.log; do
  jq --arg rid &quot;$REQUEST_ID&quot; &#39;select(.requestId == $rid or .correlationId == $rid)&#39; &quot;$f&quot; 2&gt;/dev/null
done | jq -s &#39;sort_by(.timestamp)[]&#39;
</code></pre>
<h2>Log Rotation and Large Files</h2>
<h3>Working with rotated/compressed logs</h3>
<pre><code class="language-bash"># Search across rotated logs (including .gz)
zgrep -i &#39;error&#39; /var/log/app.log*

# Search today&#39;s and yesterday&#39;s logs
zgrep -i &#39;error&#39; /var/log/app.log /var/log/app.log.1

# Decompress, filter, and recompress
zcat app.log.3.gz | grep &#39;ERROR&#39; | gzip &gt; errors-day3.gz
</code></pre>
<h3>Sampling large files</h3>
<pre><code class="language-bash"># Random sample of 1000 lines
shuf -n 1000 huge.log &gt; sample.log

# Every 100th line
awk &#39;NR % 100 == 0&#39; huge.log &gt; sample.log

# First and last 500 lines
{ head -500 huge.log; echo &quot;--- TRUNCATED ---&quot;; tail -500 huge.log; } &gt; excerpt.log
</code></pre>
<h2>Tips</h2>
<ul>
<li>Always search for a <strong>request ID or correlation ID</strong> first ‚Äî it narrows the haystack faster than timestamps or error messages.</li>
<li>Use <code>--line-buffered</code> with <code>grep</code> when piping from <code>tail -f</code> so output isn&#39;t delayed by buffering.</li>
<li>Normalize IDs and numbers before grouping errors (<code>sed &#39;s/[0-9a-f]\{8,\}/ID/g&#39;</code>) to collapse duplicates that differ only by ID.</li>
<li>For JSON logs, <code>jq</code> is indispensable. Install it if it&#39;s not available: <code>apt install jq</code> / <code>brew install jq</code>.</li>
<li>Structured logging (JSON) is always worth the setup cost. It makes every analysis task easier: filtering, grouping, correlation, and alerting all become <code>jq</code> one-liners.</li>
<li>When debugging a production issue: get the <strong>time window</strong> and <strong>affected user/request ID</strong> first, then filter logs to that scope before reading anything.</li>
<li><code>awk</code> is faster than <code>grep | sort | uniq -c</code> pipelines for large files. Use it for counting and aggregation.</li>
</ul>

                </div>
              </div>
            </article>
            <aside class="skill-page-sidebar">
              <div class="sidebar-card">
                <div class="sidebar-title">Actions</div>
                <a href="https://github.com/openclaw/skills/tree/main/skills/gitgoodordietrying/log-analyzer/SKILL.md" target="_blank" rel="noopener" class="sidebar-btn sidebar-btn-primary">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/></svg>
                  View on GitHub
                </a>
                <a href="https://clawdhub.com/gitgoodordietrying/log-analyzer" target="_blank" rel="noopener" class="sidebar-btn sidebar-btn-clawdhub">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"/><line x1="2" y1="12" x2="22" y2="12"/></svg>
                  View on ClawdHub
                </a>
                <a href="https://raw.githubusercontent.com/openclaw/skills/main/skills/gitgoodordietrying/log-analyzer/SKILL.md" download="SKILL.md" class="sidebar-btn sidebar-btn-secondary">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/><polyline points="7 10 12 15 17 10"/><line x1="12" y1="15" x2="12" y2="3"/></svg>
                  Download SKILL.md
                </a>
                <button onclick="sendToSecurityAuditor()" class="sidebar-btn sidebar-btn-security">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 22s8-4 8-10V5l-8-3-8 3v7c0 6 8 10 8 10z"/></svg>
                  Security Check
                </button>
              </div>
              <div class="sidebar-card">
                <div class="sidebar-title">Details</div>
                <div class="sidebar-info">
                  <div class="sidebar-info-item">
                    <span class="sidebar-info-label">Author</span>
                    <span class="sidebar-info-value">@gitgoodordietrying</span>
                  </div>
                  <div class="sidebar-info-item">
                    <span class="sidebar-info-label">Category</span>
                    <span class="sidebar-info-value">DevOps & Cloud</span>
                  </div>
                </div>
              </div>
            </aside>
          </div>
        
  <footer class="footer">
    <div class="footer-inner">
      <p class="footer-text" style="margin-bottom: 8px;"><a href="https://github.com/neonone123/moltdirectory" target="_blank" rel="noopener" style="color: var(--accent); text-decoration: none;">View on GitHub</a></p>
      <p class="footer-text" style="opacity: 0.6; font-size: 13px;">OpenClawDirectory.com is a community-run project and is not affiliated with the official OpenClaw team or Peter Steinberger. We are just fans of the lobster.</p>
    </div>
  </footer>
  <script>
    function toggleTheme() {
      const html = document.documentElement;
      const currentTheme = html.getAttribute('data-theme');
      const newTheme = currentTheme === 'light' ? 'dark' : 'light';
      if (newTheme === 'light') {
        html.setAttribute('data-theme', 'light');
      } else {
        html.removeAttribute('data-theme');
      }
      localStorage.setItem('theme', newTheme);
    }
    
    function copySkillContent(btn) {
      const wrapper = btn.closest('.skill-source-wrapper');
      const content = wrapper.querySelector('.markdown-content');
      if (content) {
        const text = content.innerText || content.textContent;
        navigator.clipboard.writeText(text).then(() => {
          btn.classList.add('copied');
          btn.innerHTML = '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="20 6 9 17 4 12"/></svg> Copied!';
          setTimeout(() => {
            btn.classList.remove('copied');
            btn.innerHTML = '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"/><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"/></svg> Copy';
          }, 2000);
        });
      }
    }

    async function sendToSecurityAuditor() {
      try {
        const contentElement = document.querySelector('.markdown-content');
        if (!contentElement) throw new Error('Could not find markdown content');
        const skillContent = contentElement.innerText || contentElement.textContent;
        localStorage.setItem('skillAuditContent', skillContent);
        window.open('/security-auditor', '_blank'); 
      } catch (error) {
        alert('Error: ' + error.message);
      }
    }

    function updateVoteWidget(widget, toolData) {
      if (!widget || !toolData) return;
      const upBtn = widget.querySelector('[data-vote="1"]');
      const downBtn = widget.querySelector('[data-vote="-1"]');
      const countNode = widget.querySelector('.vote-count');
      widget.dataset.rankScore = String(toolData.rankScore ?? 0);
      widget.dataset.viewerVote = String(toolData.viewerVote ?? 0);

      if (countNode) {
        countNode.textContent = toolData.displayCount || 'New';
      }
      if (upBtn) {
        upBtn.classList.toggle('is-active', Number(toolData.viewerVote) === 1);
      }
      if (downBtn) {
        downBtn.classList.toggle('is-active', Number(toolData.viewerVote) === -1);
      }
    }

    function setWidgetBusy(widget, busy) {
      widget.dataset.busy = busy ? '1' : '0';
      widget.querySelectorAll('.vote-btn').forEach((btn) => {
        btn.disabled = busy;
      });
    }

    function applySortMode(grid, mode) {
      const cards = [...grid.querySelectorAll('.skill-card[data-tool-id]')];
      cards.sort((a, b) => {
        if (mode === 'community') {
          const scoreDiff = Number(b.dataset.rankScore || 0) - Number(a.dataset.rankScore || 0);
          if (scoreDiff !== 0) return scoreDiff;
        }
        return Number(a.dataset.originalIndex || 0) - Number(b.dataset.originalIndex || 0);
      });
      cards.forEach((card) => grid.appendChild(card));
    }

    function bindSortToggle(toolbar, grid) {
      const buttons = toolbar.querySelectorAll('.sort-toggle-btn');
      const status = toolbar.querySelector('.sort-status');
      buttons.forEach((btn) => {
        btn.addEventListener('click', () => {
          const mode = btn.dataset.sortMode;
          buttons.forEach((b) => b.classList.toggle('is-active', b === btn));
          applySortMode(grid, mode);
          status.textContent = mode === 'community' ? 'Community ranking active' : 'Original order active';
        });
      });
    }

    async function fetchScores(categoryId, toolIds) {
      const params = new URLSearchParams({
        categoryId,
        toolIds: toolIds.join(',')
      });
      const response = await fetch('/api/v1/scores?' + params.toString(), {
        method: 'GET',
        credentials: 'same-origin'
      });
      if (!response.ok) {
        throw new Error('Unable to fetch vote scores');
      }
      return response.json();
    }

    async function submitVote(widget, voteValue) {
      const categoryId = widget.dataset.categoryId;
      const toolId = widget.dataset.toolId;
      setWidgetBusy(widget, true);
      try {
        const response = await fetch('/api/v1/vote', {
          method: 'POST',
          credentials: 'same-origin',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            categoryId,
            toolId,
            vote: voteValue
          })
        });
        const payload = await response.json().catch(() => ({}));
        if (!response.ok) {
          throw new Error(payload.error || 'Vote request failed');
        }
        if (payload.tool) {
          updateVoteWidget(widget, payload.tool);
          const card = widget.closest('.skill-card[data-tool-id]');
          if (card) {
            card.dataset.rankScore = String(payload.tool.rankScore ?? 0);
          }
        }
      } catch (error) {
        console.error(error);
      } finally {
        setWidgetBusy(widget, false);
      }
    }

    document.addEventListener('DOMContentLoaded', async () => {
      const widgets = [...document.querySelectorAll('.vote-widget[data-category-id][data-tool-id]')];
      if (widgets.length === 0) return;

      const grouped = new Map();
      widgets.forEach((widget) => {
        const key = widget.dataset.categoryId;
        if (!grouped.has(key)) grouped.set(key, new Map());
        grouped.get(key).set(widget.dataset.toolId, widget);
      });

      for (const [categoryId, widgetMap] of grouped.entries()) {
        const toolIds = [...widgetMap.keys()];
        try {
          const data = await fetchScores(categoryId, toolIds);
          const byTool = new Map((data.tools || []).map((tool) => [tool.toolId, tool]));
          for (const [toolId, widget] of widgetMap.entries()) {
            const toolData = byTool.get(toolId);
            if (toolData) {
              updateVoteWidget(widget, toolData);
              const card = widget.closest('.skill-card[data-tool-id]');
              if (card) {
                card.dataset.rankScore = String(toolData.rankScore ?? 0);
              }
            }
          }
        } catch (error) {
          console.error(error);
        }
      }

      widgets.forEach((widget) => {
        widget.querySelectorAll('.vote-btn').forEach((btn) => {
          btn.addEventListener('click', (event) => {
            event.preventDefault();
            event.stopPropagation();
            if (widget.dataset.busy === '1') return;
            const voteValue = Number(btn.dataset.vote);
            submitVote(widget, voteValue).then(() => {
              const grid = widget.closest('.skills-grid[data-category-id]');
              const toolbar = document.querySelector('.sort-toolbar[data-category-id="' + widget.dataset.categoryId + '"]');
              const communityBtn = toolbar ? toolbar.querySelector('.sort-toggle-btn[data-sort-mode="community"]') : null;
              if (grid && communityBtn && communityBtn.classList.contains('is-active')) {
                applySortMode(grid, 'community');
              }
            });
          });
        });
      });

      document.querySelectorAll('.skills-grid[data-category-id]').forEach((grid) => {
        const categoryId = grid.dataset.categoryId;
        const toolbar = document.querySelector('.sort-toolbar[data-category-id="' + categoryId + '"]');
        if (!toolbar) return;
        bindSortToggle(toolbar, grid);
        applySortMode(grid, 'community');
      });
    });
  </script>
</body>
</html>