<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Azure AI Evaluation SDK for Python">
  <title>azure-ai-evaluation-py - OpenClaw Directory</title>
  <link rel="canonical" href="https://moltdirectory.com/devops-cloud/azure-ai-evaluation-py/">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ü¶û</text></svg>">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/style.css">
  <script>
    // Apply saved theme before page renders to prevent flash
    (function() {
      const savedTheme = localStorage.getItem('theme') || 'dark';
      if (savedTheme === 'light') {
        document.documentElement.setAttribute('data-theme', 'light');
      }
    })();
  </script>
</head>
<body>
  <header class="header">
    <div class="header-inner">
      <a href="/" class="logo">

        <span class="logo-text">OpenClaw Directory</span>
      </a>
      <nav class="header-links">
        <a href="/start-here/" class="header-link">Start Here</a>
        <a href="/security-auditor" class="header-link">Security Auditor</a>
        <a href="https://github.com/neonone123/moltdirectory/issues/new?template=add-skill.yml" class="header-link" target="_blank" rel="noopener">Add Skill</a>
        <button class="theme-toggle" aria-label="Toggle theme" onclick="toggleTheme()">
          <svg class="icon-moon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/></svg>
          <svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
        </button>
        <a href="https://www.reddit.com/r/OpenClawDirectory/" class="header-link" target="_blank" rel="noopener" aria-label="Community">
          <svg viewBox="0 0 16 16" fill="currentColor" width="28" height="28"><path d="M6.167 8a.83.83 0 0 0-.83.83c0 .459.372.84.83.831a.831.831 0 0 0 0-1.661m1.843 3.647c.315 0 1.403-.038 1.976-.611a.23.23 0 0 0 0-.306.213.213 0 0 0-.306 0c-.353.363-1.126.487-1.67.487-.545 0-1.308-.124-1.671-.487a.213.213 0 0 0-.306 0 .213.213 0 0 0 0 .306c.564.563 1.652.61 1.977.61zm.992-2.807c0 .458.373.83.831.83s.83-.381.83-.83a.831.831 0 0 0-1.66 0z"/><path d="M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0m-3.828-1.165c-.315 0-.602.124-.812.325-.801-.573-1.9-.945-3.121-.993l.534-2.501 1.738.372a.83.83 0 1 0 .83-.869.83.83 0 0 0-.744.468l-1.938-.41a.2.2 0 0 0-.153.028.2.2 0 0 0-.086.134l-.592 2.788c-1.24.038-2.358.41-3.17.992-.21-.2-.496-.324-.81-.324a1.163 1.163 0 0 0-.478 2.224q-.03.17-.029.353c0 1.795 2.091 3.256 4.669 3.256s4.668-1.451 4.668-3.256c0-.114-.01-.238-.029-.353.401-.181.688-.592.688-1.069 0-.65-.525-1.165-1.165-1.165"/></svg>
        </a>
      </nav>
    </div>
  </header>
  
          <section class="skill-page-header">
            <div class="skill-page-header-inner">
              <a href="/devops-cloud/" class="back-link">‚Üê Back to DevOps & Cloud</a>
              <div class="skill-page-meta">
                <a href="/devops-cloud/" class="skill-page-category">DevOps & Cloud</a>
                <span class="skill-page-author">by @thegovind</span>
              </div>
              <h1 class="skill-page-title">azure-ai-evaluation-py</h1>
              <p class="skill-page-desc">Azure AI Evaluation SDK for Python</p>
              <div class="vote-widget skill-page-vote" data-category-id="devops-cloud" data-tool-id="azure-ai-evaluation-py">
                <button type="button" class="vote-btn" data-vote="1" aria-label="Upvote azure-ai-evaluation-py">‚ñ≤</button>
                <span class="vote-count">New</span>
                <button type="button" class="vote-btn" data-vote="-1" aria-label="Downvote azure-ai-evaluation-py">‚ñº</button>
              </div>
            </div>
          </section>
          <div class="skill-page-body">
            <article class="skill-page-content">
              <div class="skill-source-wrapper">
                <div class="skill-source-header">
                  <div class="skill-source-title">Source Code</div>
                  <button class="copy-btn" onclick="copySkillContent(this)">
                    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"/><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"/></svg>
                    Copy
                  </button>
                </div>
                <div class="markdown-content">
                  <h1>Azure AI Evaluation SDK for Python</h1>
<p>Assess generative AI application performance with built-in and custom evaluators.</p>
<h2>Installation</h2>
<pre><code class="language-bash">pip install azure-ai-evaluation

# With remote evaluation support
pip install azure-ai-evaluation[remote]
</code></pre>
<h2>Environment Variables</h2>
<pre><code class="language-bash"># For AI-assisted evaluators
AZURE_OPENAI_ENDPOINT=https://&lt;resource&gt;.openai.azure.com
AZURE_OPENAI_API_KEY=&lt;your-api-key&gt;
AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini

# For Foundry project integration
AIPROJECT_CONNECTION_STRING=&lt;your-connection-string&gt;
</code></pre>
<h2>Built-in Evaluators</h2>
<h3>Quality Evaluators (AI-Assisted)</h3>
<pre><code class="language-python">from azure.ai.evaluation import (
    GroundednessEvaluator,
    RelevanceEvaluator,
    CoherenceEvaluator,
    FluencyEvaluator,
    SimilarityEvaluator,
    RetrievalEvaluator
)

# Initialize with Azure OpenAI model config
model_config = {
    &quot;azure_endpoint&quot;: os.environ[&quot;AZURE_OPENAI_ENDPOINT&quot;],
    &quot;api_key&quot;: os.environ[&quot;AZURE_OPENAI_API_KEY&quot;],
    &quot;azure_deployment&quot;: os.environ[&quot;AZURE_OPENAI_DEPLOYMENT&quot;]
}

groundedness = GroundednessEvaluator(model_config)
relevance = RelevanceEvaluator(model_config)
coherence = CoherenceEvaluator(model_config)
</code></pre>
<h3>Quality Evaluators (NLP-based)</h3>
<pre><code class="language-python">from azure.ai.evaluation import (
    F1ScoreEvaluator,
    RougeScoreEvaluator,
    BleuScoreEvaluator,
    GleuScoreEvaluator,
    MeteorScoreEvaluator
)

f1 = F1ScoreEvaluator()
rouge = RougeScoreEvaluator()
bleu = BleuScoreEvaluator()
</code></pre>
<h3>Safety Evaluators</h3>
<pre><code class="language-python">from azure.ai.evaluation import (
    ViolenceEvaluator,
    SexualEvaluator,
    SelfHarmEvaluator,
    HateUnfairnessEvaluator,
    IndirectAttackEvaluator,
    ProtectedMaterialEvaluator
)

violence = ViolenceEvaluator(azure_ai_project=project_scope)
sexual = SexualEvaluator(azure_ai_project=project_scope)
</code></pre>
<h2>Single Row Evaluation</h2>
<pre><code class="language-python">from azure.ai.evaluation import GroundednessEvaluator

groundedness = GroundednessEvaluator(model_config)

result = groundedness(
    query=&quot;What is Azure AI?&quot;,
    context=&quot;Azure AI is Microsoft&#39;s AI platform...&quot;,
    response=&quot;Azure AI provides AI services and tools.&quot;
)

print(f&quot;Groundedness score: {result[&#39;groundedness&#39;]}&quot;)
print(f&quot;Reason: {result[&#39;groundedness_reason&#39;]}&quot;)
</code></pre>
<h2>Batch Evaluation with evaluate()</h2>
<pre><code class="language-python">from azure.ai.evaluation import evaluate

result = evaluate(
    data=&quot;test_data.jsonl&quot;,
    evaluators={
        &quot;groundedness&quot;: groundedness,
        &quot;relevance&quot;: relevance,
        &quot;coherence&quot;: coherence
    },
    evaluator_config={
        &quot;default&quot;: {
            &quot;column_mapping&quot;: {
                &quot;query&quot;: &quot;${data.query}&quot;,
                &quot;context&quot;: &quot;${data.context}&quot;,
                &quot;response&quot;: &quot;${data.response}&quot;
            }
        }
    }
)

print(result[&quot;metrics&quot;])
</code></pre>
<h2>Composite Evaluators</h2>
<pre><code class="language-python">from azure.ai.evaluation import QAEvaluator, ContentSafetyEvaluator

# All quality metrics in one
qa_evaluator = QAEvaluator(model_config)

# All safety metrics in one
safety_evaluator = ContentSafetyEvaluator(azure_ai_project=project_scope)

result = evaluate(
    data=&quot;data.jsonl&quot;,
    evaluators={
        &quot;qa&quot;: qa_evaluator,
        &quot;content_safety&quot;: safety_evaluator
    }
)
</code></pre>
<h2>Evaluate Application Target</h2>
<pre><code class="language-python">from azure.ai.evaluation import evaluate
from my_app import chat_app  # Your application

result = evaluate(
    data=&quot;queries.jsonl&quot;,
    target=chat_app,  # Callable that takes query, returns response
    evaluators={
        &quot;groundedness&quot;: groundedness
    },
    evaluator_config={
        &quot;default&quot;: {
            &quot;column_mapping&quot;: {
                &quot;query&quot;: &quot;${data.query}&quot;,
                &quot;context&quot;: &quot;${outputs.context}&quot;,
                &quot;response&quot;: &quot;${outputs.response}&quot;
            }
        }
    }
)
</code></pre>
<h2>Custom Evaluators</h2>
<h3>Code-Based</h3>
<pre><code class="language-python">from azure.ai.evaluation import evaluator

@evaluator
def word_count_evaluator(response: str) -&gt; dict:
    return {&quot;word_count&quot;: len(response.split())}

# Use in evaluate()
result = evaluate(
    data=&quot;data.jsonl&quot;,
    evaluators={&quot;word_count&quot;: word_count_evaluator}
)
</code></pre>
<h3>Prompt-Based</h3>
<pre><code class="language-python">from azure.ai.evaluation import PromptChatTarget

class CustomEvaluator:
    def __init__(self, model_config):
        self.model = PromptChatTarget(model_config)
    
    def __call__(self, query: str, response: str) -&gt; dict:
        prompt = f&quot;Rate this response 1-5: Query: {query}, Response: {response}&quot;
        result = self.model.send_prompt(prompt)
        return {&quot;custom_score&quot;: int(result)}
</code></pre>
<h2>Log to Foundry Project</h2>
<pre><code class="language-python">from azure.ai.projects import AIProjectClient
from azure.identity import DefaultAzureCredential

project = AIProjectClient.from_connection_string(
    conn_str=os.environ[&quot;AIPROJECT_CONNECTION_STRING&quot;],
    credential=DefaultAzureCredential()
)

result = evaluate(
    data=&quot;data.jsonl&quot;,
    evaluators={&quot;groundedness&quot;: groundedness},
    azure_ai_project=project.scope  # Logs results to Foundry
)

print(f&quot;View results: {result[&#39;studio_url&#39;]}&quot;)
</code></pre>
<h2>Evaluator Reference</h2>
<table>
<thead>
<tr>
<th>Evaluator</th>
<th>Type</th>
<th>Metrics</th>
</tr>
</thead>
<tbody><tr>
<td><code>GroundednessEvaluator</code></td>
<td>AI</td>
<td>groundedness (1-5)</td>
</tr>
<tr>
<td><code>RelevanceEvaluator</code></td>
<td>AI</td>
<td>relevance (1-5)</td>
</tr>
<tr>
<td><code>CoherenceEvaluator</code></td>
<td>AI</td>
<td>coherence (1-5)</td>
</tr>
<tr>
<td><code>FluencyEvaluator</code></td>
<td>AI</td>
<td>fluency (1-5)</td>
</tr>
<tr>
<td><code>SimilarityEvaluator</code></td>
<td>AI</td>
<td>similarity (1-5)</td>
</tr>
<tr>
<td><code>RetrievalEvaluator</code></td>
<td>AI</td>
<td>retrieval (1-5)</td>
</tr>
<tr>
<td><code>F1ScoreEvaluator</code></td>
<td>NLP</td>
<td>f1_score (0-1)</td>
</tr>
<tr>
<td><code>RougeScoreEvaluator</code></td>
<td>NLP</td>
<td>rouge scores</td>
</tr>
<tr>
<td><code>ViolenceEvaluator</code></td>
<td>Safety</td>
<td>violence (0-7)</td>
</tr>
<tr>
<td><code>SexualEvaluator</code></td>
<td>Safety</td>
<td>sexual (0-7)</td>
</tr>
<tr>
<td><code>SelfHarmEvaluator</code></td>
<td>Safety</td>
<td>self_harm (0-7)</td>
</tr>
<tr>
<td><code>HateUnfairnessEvaluator</code></td>
<td>Safety</td>
<td>hate_unfairness (0-7)</td>
</tr>
<tr>
<td><code>QAEvaluator</code></td>
<td>Composite</td>
<td>All quality metrics</td>
</tr>
<tr>
<td><code>ContentSafetyEvaluator</code></td>
<td>Composite</td>
<td>All safety metrics</td>
</tr>
</tbody></table>
<h2>Best Practices</h2>
<ol>
<li><strong>Use composite evaluators</strong> for comprehensive assessment</li>
<li><strong>Map columns correctly</strong> ‚Äî mismatched columns cause silent failures</li>
<li><strong>Log to Foundry</strong> for tracking and comparison across runs</li>
<li><strong>Create custom evaluators</strong> for domain-specific metrics</li>
<li><strong>Use NLP evaluators</strong> when you have ground truth answers</li>
<li><strong>Safety evaluators require</strong> Azure AI project scope</li>
<li><strong>Batch evaluation</strong> is more efficient than single-row loops</li>
</ol>
<h2>Reference Files</h2>
<table>
<thead>
<tr>
<th>File</th>
<th>Contents</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://github.com/openclaw/skills/blob/main/skills/thegovind/azure-ai-evaluation-py/references/built-in-evaluators.md">references/built-in-evaluators.md</a></td>
<td>Detailed patterns for AI-assisted, NLP-based, and Safety evaluators with configuration tables</td>
</tr>
<tr>
<td><a href="https://github.com/openclaw/skills/blob/main/skills/thegovind/azure-ai-evaluation-py/references/custom-evaluators.md">references/custom-evaluators.md</a></td>
<td>Creating code-based and prompt-based custom evaluators, testing patterns</td>
</tr>
<tr>
<td><a href="scripts/run_batch_evaluation.py">scripts/run_batch_evaluation.py</a></td>
<td>CLI tool for running batch evaluations with quality, safety, and custom evaluators</td>
</tr>
</tbody></table>

                </div>
              </div>
            </article>
            <aside class="skill-page-sidebar">
              <div class="sidebar-card">
                <div class="sidebar-title">Actions</div>
                <a href="https://github.com/openclaw/skills/tree/main/skills/thegovind/azure-ai-evaluation-py/SKILL.md" target="_blank" rel="noopener" class="sidebar-btn sidebar-btn-primary">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/></svg>
                  View on GitHub
                </a>
                <a href="https://clawdhub.com/thegovind/azure-ai-evaluation-py" target="_blank" rel="noopener" class="sidebar-btn sidebar-btn-clawdhub">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"/><line x1="2" y1="12" x2="22" y2="12"/></svg>
                  View on ClawdHub
                </a>
                <a href="https://raw.githubusercontent.com/openclaw/skills/main/skills/thegovind/azure-ai-evaluation-py/SKILL.md" download="SKILL.md" class="sidebar-btn sidebar-btn-secondary">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/><polyline points="7 10 12 15 17 10"/><line x1="12" y1="15" x2="12" y2="3"/></svg>
                  Download SKILL.md
                </a>
                <button onclick="sendToSecurityAuditor()" class="sidebar-btn sidebar-btn-security">
                  <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 22s8-4 8-10V5l-8-3-8 3v7c0 6 8 10 8 10z"/></svg>
                  Security Check
                </button>
              </div>
              <div class="sidebar-card">
                <div class="sidebar-title">Details</div>
                <div class="sidebar-info">
                  <div class="sidebar-info-item">
                    <span class="sidebar-info-label">Author</span>
                    <span class="sidebar-info-value">@thegovind</span>
                  </div>
                  <div class="sidebar-info-item">
                    <span class="sidebar-info-label">Category</span>
                    <span class="sidebar-info-value">DevOps & Cloud</span>
                  </div>
                </div>
              </div>
            </aside>
          </div>
        
  <footer class="footer">
    <div class="footer-inner">
      <p class="footer-text" style="margin-bottom: 8px;"><a href="https://github.com/neonone123/moltdirectory" target="_blank" rel="noopener" style="color: var(--accent); text-decoration: none;">View on GitHub</a></p>
      <p class="footer-text" style="opacity: 0.6; font-size: 13px;">OpenClawDirectory.com is a community-run project and is not affiliated with the official OpenClaw team or Peter Steinberger. We are just fans of the lobster.</p>
    </div>
  </footer>
  <script>
    function toggleTheme() {
      const html = document.documentElement;
      const currentTheme = html.getAttribute('data-theme');
      const newTheme = currentTheme === 'light' ? 'dark' : 'light';
      if (newTheme === 'light') {
        html.setAttribute('data-theme', 'light');
      } else {
        html.removeAttribute('data-theme');
      }
      localStorage.setItem('theme', newTheme);
    }
    
    function copySkillContent(btn) {
      const wrapper = btn.closest('.skill-source-wrapper');
      const content = wrapper.querySelector('.markdown-content');
      if (content) {
        const text = content.innerText || content.textContent;
        navigator.clipboard.writeText(text).then(() => {
          btn.classList.add('copied');
          btn.innerHTML = '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polyline points="20 6 9 17 4 12"/></svg> Copied!';
          setTimeout(() => {
            btn.classList.remove('copied');
            btn.innerHTML = '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"/><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"/></svg> Copy';
          }, 2000);
        });
      }
    }

    async function sendToSecurityAuditor() {
      try {
        const contentElement = document.querySelector('.markdown-content');
        if (!contentElement) throw new Error('Could not find markdown content');
        const skillContent = contentElement.innerText || contentElement.textContent;
        localStorage.setItem('skillAuditContent', skillContent);
        window.open('/security-auditor', '_blank'); 
      } catch (error) {
        alert('Error: ' + error.message);
      }
    }

    function updateVoteWidget(widget, toolData) {
      if (!widget || !toolData) return;
      const upBtn = widget.querySelector('[data-vote="1"]');
      const downBtn = widget.querySelector('[data-vote="-1"]');
      const countNode = widget.querySelector('.vote-count');
      widget.dataset.rankScore = String(toolData.rankScore ?? 0);
      widget.dataset.viewerVote = String(toolData.viewerVote ?? 0);

      if (countNode) {
        countNode.textContent = toolData.displayCount || 'New';
      }
      if (upBtn) {
        upBtn.classList.toggle('is-active', Number(toolData.viewerVote) === 1);
      }
      if (downBtn) {
        downBtn.classList.toggle('is-active', Number(toolData.viewerVote) === -1);
      }
    }

    function setWidgetBusy(widget, busy) {
      widget.dataset.busy = busy ? '1' : '0';
      widget.querySelectorAll('.vote-btn').forEach((btn) => {
        btn.disabled = busy;
      });
    }

    function applySortMode(grid, mode) {
      const cards = [...grid.querySelectorAll('.skill-card[data-tool-id]')];
      cards.sort((a, b) => {
        if (mode === 'community') {
          const scoreDiff = Number(b.dataset.rankScore || 0) - Number(a.dataset.rankScore || 0);
          if (scoreDiff !== 0) return scoreDiff;
        }
        return Number(a.dataset.originalIndex || 0) - Number(b.dataset.originalIndex || 0);
      });
      cards.forEach((card) => grid.appendChild(card));
    }

    function bindSortToggle(toolbar, grid) {
      const buttons = toolbar.querySelectorAll('.sort-toggle-btn');
      const status = toolbar.querySelector('.sort-status');
      buttons.forEach((btn) => {
        btn.addEventListener('click', () => {
          const mode = btn.dataset.sortMode;
          buttons.forEach((b) => b.classList.toggle('is-active', b === btn));
          applySortMode(grid, mode);
          status.textContent = mode === 'community' ? 'Community ranking active' : 'Original order active';
        });
      });
    }

    async function fetchScores(categoryId, toolIds) {
      const params = new URLSearchParams({
        categoryId,
        toolIds: toolIds.join(',')
      });
      const response = await fetch('/api/v1/scores?' + params.toString(), {
        method: 'GET',
        credentials: 'same-origin'
      });
      if (!response.ok) {
        throw new Error('Unable to fetch vote scores');
      }
      return response.json();
    }

    async function submitVote(widget, voteValue) {
      const categoryId = widget.dataset.categoryId;
      const toolId = widget.dataset.toolId;
      setWidgetBusy(widget, true);
      try {
        const response = await fetch('/api/v1/vote', {
          method: 'POST',
          credentials: 'same-origin',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            categoryId,
            toolId,
            vote: voteValue
          })
        });
        const payload = await response.json().catch(() => ({}));
        if (!response.ok) {
          throw new Error(payload.error || 'Vote request failed');
        }
        if (payload.tool) {
          updateVoteWidget(widget, payload.tool);
          const card = widget.closest('.skill-card[data-tool-id]');
          if (card) {
            card.dataset.rankScore = String(payload.tool.rankScore ?? 0);
          }
        }
      } catch (error) {
        console.error(error);
      } finally {
        setWidgetBusy(widget, false);
      }
    }

    document.addEventListener('DOMContentLoaded', async () => {
      const widgets = [...document.querySelectorAll('.vote-widget[data-category-id][data-tool-id]')];
      if (widgets.length === 0) return;

      const grouped = new Map();
      widgets.forEach((widget) => {
        const key = widget.dataset.categoryId;
        if (!grouped.has(key)) grouped.set(key, new Map());
        grouped.get(key).set(widget.dataset.toolId, widget);
      });

      for (const [categoryId, widgetMap] of grouped.entries()) {
        const toolIds = [...widgetMap.keys()];
        try {
          const data = await fetchScores(categoryId, toolIds);
          const byTool = new Map((data.tools || []).map((tool) => [tool.toolId, tool]));
          for (const [toolId, widget] of widgetMap.entries()) {
            const toolData = byTool.get(toolId);
            if (toolData) {
              updateVoteWidget(widget, toolData);
              const card = widget.closest('.skill-card[data-tool-id]');
              if (card) {
                card.dataset.rankScore = String(toolData.rankScore ?? 0);
              }
            }
          }
        } catch (error) {
          console.error(error);
        }
      }

      widgets.forEach((widget) => {
        widget.querySelectorAll('.vote-btn').forEach((btn) => {
          btn.addEventListener('click', (event) => {
            event.preventDefault();
            event.stopPropagation();
            if (widget.dataset.busy === '1') return;
            const voteValue = Number(btn.dataset.vote);
            submitVote(widget, voteValue).then(() => {
              const grid = widget.closest('.skills-grid[data-category-id]');
              const toolbar = document.querySelector('.sort-toolbar[data-category-id="' + widget.dataset.categoryId + '"]');
              const communityBtn = toolbar ? toolbar.querySelector('.sort-toggle-btn[data-sort-mode="community"]') : null;
              if (grid && communityBtn && communityBtn.classList.contains('is-active')) {
                applySortMode(grid, 'community');
              }
            });
          });
        });
      });

      document.querySelectorAll('.skills-grid[data-category-id]').forEach((grid) => {
        const categoryId = grid.dataset.categoryId;
        const toolbar = document.querySelector('.sort-toolbar[data-category-id="' + categoryId + '"]');
        if (!toolbar) return;
        bindSortToggle(toolbar, grid);
        applySortMode(grid, 'community');
      });
    });
  </script>
</body>
</html>